{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, 3, padding=1),  # 1*3*3*4 + 4 = 40 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(4),              # 8 params\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, 3, padding=1),  # 4*3*3*8 + 8 = 296 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),              # 16 params\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        \n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(8, 12, 3, padding=1), # 8*3*3*12 + 12 = 876 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),             # 24 params\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        \n",
        "        # 12 channels * 3 * 3 = 108 neurons after three max pools (28->14->7->3)\n",
        "        self.fc1 = nn.Linear(12 * 3 * 3, 10)  # 108*10 + 10 = 1090 params\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, 12 * 3 * 3)  # Flatten\n",
        "        x = F.dropout(x, p=0.1)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 4, 14, 14]            --\n",
              "│    └─Conv2d: 2-1                       [1, 4, 28, 28]            40\n",
              "│    └─ReLU: 2-2                         [1, 4, 28, 28]            --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 4, 28, 28]            8\n",
              "│    └─MaxPool2d: 2-4                    [1, 4, 14, 14]            --\n",
              "├─Sequential: 1-2                        [1, 8, 7, 7]              --\n",
              "│    └─Conv2d: 2-5                       [1, 8, 14, 14]            296\n",
              "│    └─ReLU: 2-6                         [1, 8, 14, 14]            --\n",
              "│    └─BatchNorm2d: 2-7                  [1, 8, 14, 14]            16\n",
              "│    └─MaxPool2d: 2-8                    [1, 8, 7, 7]              --\n",
              "│    └─Dropout: 2-9                      [1, 8, 7, 7]              --\n",
              "├─Sequential: 1-3                        [1, 12, 3, 3]             --\n",
              "│    └─Conv2d: 2-10                      [1, 12, 7, 7]             876\n",
              "│    └─ReLU: 2-11                        [1, 12, 7, 7]             --\n",
              "│    └─BatchNorm2d: 2-12                 [1, 12, 7, 7]             24\n",
              "│    └─MaxPool2d: 2-13                   [1, 12, 3, 3]             --\n",
              "│    └─Dropout: 2-14                     [1, 12, 3, 3]             --\n",
              "├─Linear: 1-4                            [1, 10]                   1,090\n",
              "==========================================================================================\n",
              "Total params: 2,350\n",
              "Trainable params: 2,350\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.08\n",
              "Params size (MB): 0.01\n",
              "Estimated Total Size (MB): 0.10\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "# Create a dummy input tensor on the correct device\n",
        "summary(model, input_size=(1, 1, 28, 28), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1456)\n",
        "batch_size = 512\n",
        "\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True} if device.type in [\"cuda\", \"mps\"] else {}\n",
        "\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "# Define the augmentation pipeline\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.0625,\n",
        "        scale_limit=0.1,\n",
        "        rotate_limit=15,\n",
        "        p=0.7,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.3),\n",
        "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
        "    A.Perspective(scale=(0.05, 0.1), p=0.3, keep_size=True, pad_mode=cv2.BORDER_CONSTANT, pad_val=0),\n",
        "\n",
        "    A.ElasticTransform(\n",
        "         alpha=1.0,\n",
        "         sigma=10.0,\n",
        "         alpha_affine=None,  # Set to None as required by newer versions\n",
        "         interpolation=cv2.INTER_LINEAR,\n",
        "         border_mode=cv2.BORDER_CONSTANT,\n",
        "         value=0,\n",
        "         p=0.3\n",
        "    ),\n",
        "    \n",
        "    # CoarseDropout as alternative to regular dropout\n",
        "    A.CoarseDropout(\n",
        "        max_holes=2,\n",
        "        max_height=8,\n",
        "        max_width=8,\n",
        "        min_holes=1,\n",
        "        fill_value=0,\n",
        "        p=0.2\n",
        "    ),\n",
        "\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Custom Dataset class to work with Albumentations\n",
        "class MNISTAlbumentations(datasets.MNIST):\n",
        "    def __init__(self, root, train=True, download=True, transform=None):\n",
        "        super().__init__(root, train=train, download=download, transform=None)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx], self.targets[idx]\n",
        "        \n",
        "        # Convert to numpy array and add channel dimension\n",
        "        img = np.array(img)\n",
        "        img = np.expand_dims(img, axis=-1)  # Add channel dimension for Albumentations\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=img)\n",
        "            img = transformed[\"image\"]\n",
        "            \n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Update the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=True, download=True, transform=train_transforms),\n",
        "    batch_size=batch_size, shuffle=True, \n",
        "    **kwargs)\n",
        "\n",
        "# Test transforms (only normalization, no augmentation)\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=False, transform=test_transforms),\n",
        "    batch_size=batch_size, shuffle=True,  \n",
        "    **kwargs)\n",
        "\n",
        "# Optional: Visualization function to check augmentations\n",
        "def visualize_augmentations(dataset, idx=0, samples=5):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(samples):\n",
        "        data = dataset[idx][0]\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            data = data.numpy()\n",
        "        if data.shape[0] == 1:  # If channels first, move to last\n",
        "            data = np.transpose(data, (1, 2, 0))\n",
        "        plt.subplot(1, samples, i + 1)\n",
        "        plt.imshow(data.squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in train dataset: 60000\n",
            "Number of samples in test dataset: 10000\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to visualize augmentations\n",
        "visualize_augmentations(train_loader.dataset)\n",
        "\n",
        "# # print number of samples in train and test dataset\n",
        "print(f\"Number of samples in train dataset: {len(train_loader.dataset)}\")\n",
        "print(f\"Number of samples in test dataset: {len(test_loader.dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch, scheduler=None):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [],
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 14):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "\n",
        "\"\"\"\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.0625,\n",
        "        scale_limit=0.1,\n",
        "        rotate_limit=15,\n",
        "        p=0.7,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.3),\n",
        "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
        "    A.Perspective(scale=(0.05, 0.1), p=0.3, keep_size=True, pad_mode=cv2.BORDER_CONSTANT, pad_val=0),\n",
        "\n",
        "    A.ElasticTransform(\n",
        "         alpha=1.0,\n",
        "         sigma=10.0,\n",
        "         alpha_affine=None,  # Set to None as required by newer versions\n",
        "         interpolation=cv2.INTER_LINEAR,\n",
        "         border_mode=cv2.BORDER_CONSTANT,\n",
        "         value=0,\n",
        "         p=0.3\n",
        "    ),\n",
        "    \n",
        "    # CoarseDropout as alternative to regular dropout\n",
        "    A.CoarseDropout(\n",
        "        max_holes=2,\n",
        "        max_height=8,\n",
        "        max_width=8,\n",
        "        min_holes=1,\n",
        "        fill_value=0,\n",
        "        p=0.2\n",
        "    ),\n",
        "\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "-\n",
        "loss=0.6580258011817932 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.68it/s]\n",
        "\n",
        "Test set: Average loss: 0.2339, Accuracy: 9299/10000 (92.99%)\n",
        "\n",
        "loss=0.3493722677230835 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.78it/s] \n",
        "\n",
        "Test set: Average loss: 0.1302, Accuracy: 9583/10000 (95.83%)\n",
        "\n",
        "loss=0.39144933223724365 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.77it/s]\n",
        "\n",
        "Test set: Average loss: 0.1068, Accuracy: 9673/10000 (96.73%)\n",
        "\n",
        "loss=0.32208719849586487 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.78it/s]\n",
        "\n",
        "Test set: Average loss: 0.0909, Accuracy: 9710/10000 (97.10%)\n",
        "\n",
        "loss=0.2897714078426361 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.77it/s] \n",
        "\n",
        "Test set: Average loss: 0.0921, Accuracy: 9717/10000 (97.17%)\n",
        "\n",
        "loss=0.35914042592048645 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.69it/s]\n",
        "\n",
        "Test set: Average loss: 0.0801, Accuracy: 9741/10000 (97.41%)\n",
        "\n",
        "loss=0.14843730628490448 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.79it/s]\n",
        "\n",
        "Test set: Average loss: 0.0731, Accuracy: 9754/10000 (97.54%)\n",
        "\n",
        "loss=0.23503129184246063 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.71it/s]\n",
        "\n",
        "Test set: Average loss: 0.0671, Accuracy: 9789/10000 (97.89%)\n",
        "\n",
        "loss=0.1971328854560852 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.80it/s] \n",
        "\n",
        "Test set: Average loss: 0.0719, Accuracy: 9778/10000 (97.78%)\n",
        "\n",
        "loss=0.29275843501091003 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.85it/s]\n",
        "\n",
        "Test set: Average loss: 0.0624, Accuracy: 9788/10000 (97.88%)\n",
        "\n",
        "loss=0.19085021317005157 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.79it/s]\n",
        "\n",
        "Test set: Average loss: 0.0594, Accuracy: 9809/10000 (98.09%)\n",
        "\n",
        "loss=0.4703753888607025 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.79it/s] \n",
        "\n",
        "Test set: Average loss: 0.0610, Accuracy: 9805/10000 (98.05%)\n",
        "\n",
        "loss=0.2123817354440689 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.76it/s] \n",
        "\n",
        "Test set: Average loss: 0.0591, Accuracy: 9792/10000 (97.92%)\n",
        "\n",
        "loss=0.35463497042655945 batch_id=117: 100%|██████████| 118/118 [00:20<00:00,  5.81it/s]\n",
        "\n",
        "Test set: Average loss: 0.0574, Accuracy: 9822/10000 (98.22%)\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### -- Variation 1 - More Aggressive Rotations and Transformations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.1,        # Increased shift\n",
        "        scale_limit=0.15,       # Increased scale\n",
        "        rotate_limit=30,        # Increased rotation\n",
        "        p=0.8,                  # Higher probability\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.4),  # Increased distortion\n",
        "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.4),             # More noise\n",
        "    A.Perspective(scale=(0.05, 0.15), p=0.4),                 # More perspective change\n",
        "    \n",
        "    A.ElasticTransform(\n",
        "         alpha=2.0,            # Increased deformation\n",
        "         sigma=15.0,\n",
        "         alpha_affine=None,\n",
        "         interpolation=cv2.INTER_LINEAR,\n",
        "         border_mode=cv2.BORDER_CONSTANT,\n",
        "         value=0,\n",
        "         p=0.4\n",
        "    ),\n",
        "    \n",
        "    A.CoarseDropout(\n",
        "        max_holes=3,           # More holes\n",
        "        max_height=10,         # Larger holes\n",
        "        max_width=10,\n",
        "        min_holes=1,\n",
        "        fill_value=0,\n",
        "        p=0.3\n",
        "    ),\n",
        "    A.Normalize(mean=[0.1307], std=[0.3081]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "loss=1.0413247346878052 batch_id=117: 100%|██████████| 118/118 [00:27<00:00,  4.30it/s]\n",
        "\n",
        "Test set: Average loss: 0.3043, Accuracy: 9221/10000 (92.21%)\n",
        "\n",
        "loss=0.6868762969970703 batch_id=117: 100%|██████████| 118/118 [00:27<00:00,  4.29it/s]\n",
        "\n",
        "Test set: Average loss: 0.2020, Accuracy: 9476/10000 (94.76%)\n",
        "\n",
        "loss=0.8287444114685059 batch_id=117: 100%|██████████| 118/118 [00:27<00:00,  4.34it/s]\n",
        "\n",
        "Test set: Average loss: 0.1684, Accuracy: 9536/10000 (95.36%)\n",
        "\n",
        "loss=0.8311219811439514 batch_id=117: 100%|██████████| 118/118 [00:27<00:00,  4.31it/s]\n",
        "\n",
        "Test set: Average loss: 0.1504, Accuracy: 9574/10000 (95.74%)\n",
        "\n",
        "loss=0.7059124112129211 batch_id=117: 100%|██████████| 118/118 [00:27<00:00,  4.33it/s]\n",
        "\n",
        "Test set: Average loss: 0.1572, Accuracy: 9549/10000 (95.49%)\n",
        "\n",
        "loss=0.7394788861274719 batch_id=117: 100%|██████████| 118/118 [00:27<00:00,  4.30it/s]\n",
        "\n",
        "Test set: Average loss: 0.1420, Accuracy: 9598/10000 (95.98%)\n",
        "\n",
        "loss=0.7396133542060852 batch_id=117: 100%|██████████| 118/118 [00:26<00:00,  4.38it/s]\n",
        "\n",
        "Test set: Average loss: 0.1404, Accuracy: 9589/10000 (95.89%)\n",
        "\n",
        "loss=0.6282297372817993 batch_id=117: 100%|██████████| 118/118 [00:27<00:00,  4.36it/s]\n",
        "\n",
        "Test set: Average loss: 0.1360, Accuracy: 9614/10000 (96.14%)\n",
        "\n",
        "loss=0.686625063419342 batch_id=117: 100%|██████████| 118/118 [00:26<00:00,  4.40it/s] \n",
        "\n",
        "Test set: Average loss: 0.1268, Accuracy: 9612/10000 (96.12%)\n",
        "\n",
        "loss=0.7198159694671631 batch_id=117: 100%|██████████| 118/118 [00:26<00:00,  4.39it/s]\n",
        "\n",
        "Test set: Average loss: 0.1326, Accuracy: 9617/10000 (96.17%)\n",
        "\n",
        "loss=0.5825936794281006 batch_id=117: 100%|██████████| 118/118 [00:27<00:00,  4.33it/s]\n",
        "\n",
        "Test set: Average loss: 0.1226, Accuracy: 9632/10000 (96.32%)\n",
        "\n",
        "loss=0.788107693195343 batch_id=117: 100%|██████████| 118/118 [00:26<00:00,  4.38it/s] \n",
        "\n",
        "Test set: Average loss: 0.1301, Accuracy: 9621/10000 (96.21%)\n",
        "\n",
        "loss=0.7037412524223328 batch_id=117: 100%|██████████| 118/118 [00:26<00:00,  4.38it/s]\n",
        "\n",
        "Test set: Average loss: 0.1246, Accuracy: 9639/10000 (96.39%)\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variation 2 - Lighter Augmentations with Focus on Noise and Dropout:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05,      # Reduced shift\n",
        "        scale_limit=0.05,      # Reduced scale\n",
        "        rotate_limit=10,       # Reduced rotation\n",
        "        p=0.6,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    A.GaussNoise(var_limit=(2.0, 15.0), p=0.5),  # More frequent but lighter noise\n",
        "    \n",
        "    A.CoarseDropout(\n",
        "        max_holes=4,           # More holes\n",
        "        max_height=6,          # Smaller holes\n",
        "        max_width=6,\n",
        "        min_holes=2,\n",
        "        fill_value=0,\n",
        "        p=0.4                  # Higher dropout probability\n",
        "    ),\n",
        "    \n",
        "    A.Blur(blur_limit=3, p=0.3),  # Added slight blur\n",
        "    A.RandomBrightnessContrast(p=0.2),  # Added brightness/contrast\n",
        "    \n",
        "    A.Normalize(mean=[0.1307], std=[0.3081]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "loss=0.5078465342521667 batch_id=117: 100%|██████████| 118/118 [00:22<00:00,  5.34it/s] \n",
        "\n",
        "Test set: Average loss: 0.1778, Accuracy: 9473/10000 (94.73%)\n",
        "\n",
        "loss=0.24720843136310577 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.48it/s]\n",
        "\n",
        "Test set: Average loss: 0.1285, Accuracy: 9598/10000 (95.98%)\n",
        "\n",
        "loss=0.2728830575942993 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.45it/s] \n",
        "\n",
        "Test set: Average loss: 0.1147, Accuracy: 9639/10000 (96.39%)\n",
        "\n",
        "loss=0.23713302612304688 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.50it/s]\n",
        "\n",
        "Test set: Average loss: 0.0977, Accuracy: 9691/10000 (96.91%)\n",
        "\n",
        "loss=0.2897968590259552 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.48it/s] \n",
        "\n",
        "Test set: Average loss: 0.0978, Accuracy: 9692/10000 (96.92%)\n",
        "\n",
        "loss=0.36567988991737366 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.40it/s]\n",
        "\n",
        "Test set: Average loss: 0.0852, Accuracy: 9713/10000 (97.13%)\n",
        "\n",
        "loss=0.2408098727464676 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.47it/s] \n",
        "\n",
        "Test set: Average loss: 0.0848, Accuracy: 9727/10000 (97.27%)\n",
        "\n",
        "loss=0.14981187880039215 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.45it/s]\n",
        "\n",
        "Test set: Average loss: 0.0774, Accuracy: 9765/10000 (97.65%)\n",
        "\n",
        "loss=0.19721554219722748 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.51it/s]\n",
        "\n",
        "Test set: Average loss: 0.0767, Accuracy: 9765/10000 (97.65%)\n",
        "\n",
        "loss=0.19081975519657135 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.50it/s]\n",
        "\n",
        "Test set: Average loss: 0.0755, Accuracy: 9752/10000 (97.52%)\n",
        "\n",
        "loss=0.2508995234966278 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.41it/s] \n",
        "\n",
        "Test set: Average loss: 0.0718, Accuracy: 9782/10000 (97.82%)\n",
        "\n",
        "loss=0.31102558970451355 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.49it/s]\n",
        "\n",
        "Test set: Average loss: 0.0677, Accuracy: 9786/10000 (97.86%)\n",
        "\n",
        "loss=0.2582463324069977 batch_id=117: 100%|██████████| 118/118 [00:21<00:00,  5.45it/s] \n",
        "\n",
        "Test set: Average loss: 0.0702, Accuracy: 9765/10000 (97.65%)\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variation 3 - Focus on Geometric Transformations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "train_transforms = A.Compose([\n",
        "    A.OneOf([\n",
        "        A.ShiftScaleRotate(\n",
        "            shift_limit=0.07,\n",
        "            scale_limit=0.1,\n",
        "            rotate_limit=20,\n",
        "            p=0.8\n",
        "        ),\n",
        "        A.Affine(\n",
        "            scale=(0.8, 1.2),\n",
        "            rotate=(-20, 20),\n",
        "            shear=(-10, 10),\n",
        "            p=0.8\n",
        "        ),\n",
        "    ], p=0.9),\n",
        "    \n",
        "    A.GridDistortion(num_steps=6, distort_limit=0.2, p=0.4),\n",
        "    A.OpticalDistortion(distort_limit=0.2, shift_limit=0.1, p=0.3),\n",
        "    \n",
        "    A.ElasticTransform(\n",
        "         alpha=1.5,\n",
        "         sigma=12.0,\n",
        "         alpha_affine=None,\n",
        "         p=0.4\n",
        "    ),\n",
        "    \n",
        "    A.CoarseDropout(\n",
        "        max_holes=2,\n",
        "        max_height=8,\n",
        "        max_width=8,\n",
        "        min_holes=1,\n",
        "        fill_value=0,\n",
        "        p=0.2\n",
        "    ),\n",
        "    \n",
        "    A.Normalize(mean=[0.1307], std=[0.3081]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "loss=0.6834432482719421 batch_id=117: 100%|██████████| 118/118 [00:25<00:00,  4.71it/s] \n",
        "\n",
        "Test set: Average loss: 0.1937, Accuracy: 9423/10000 (94.23%)\n",
        "\n",
        "loss=0.3644828498363495 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.77it/s] \n",
        "\n",
        "Test set: Average loss: 0.1415, Accuracy: 9577/10000 (95.77%)\n",
        "\n",
        "loss=0.37179961800575256 batch_id=117: 100%|██████████| 118/118 [00:25<00:00,  4.71it/s]\n",
        "\n",
        "Test set: Average loss: 0.1206, Accuracy: 9652/10000 (96.52%)\n",
        "\n",
        "loss=0.46558475494384766 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.76it/s]\n",
        "\n",
        "Test set: Average loss: 0.1033, Accuracy: 9701/10000 (97.01%)\n",
        "\n",
        "loss=0.2922475337982178 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.75it/s] \n",
        "\n",
        "Test set: Average loss: 0.1006, Accuracy: 9696/10000 (96.96%)\n",
        "\n",
        "loss=0.40941527485847473 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.74it/s]\n",
        "\n",
        "Test set: Average loss: 0.0930, Accuracy: 9704/10000 (97.04%)\n",
        "\n",
        "loss=0.3747505247592926 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.75it/s] \n",
        "\n",
        "Test set: Average loss: 0.0977, Accuracy: 9692/10000 (96.92%)\n",
        "\n",
        "loss=0.26809120178222656 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.74it/s]\n",
        "\n",
        "Test set: Average loss: 0.0844, Accuracy: 9744/10000 (97.44%)\n",
        "\n",
        "loss=0.3604784905910492 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.74it/s] \n",
        "\n",
        "Test set: Average loss: 0.0853, Accuracy: 9734/10000 (97.34%)\n",
        "\n",
        "loss=0.37283453345298767 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.73it/s]\n",
        "\n",
        "Test set: Average loss: 0.0805, Accuracy: 9738/10000 (97.38%)\n",
        "\n",
        "loss=0.21596936881542206 batch_id=117: 100%|██████████| 118/118 [00:25<00:00,  4.70it/s]\n",
        "\n",
        "Test set: Average loss: 0.0787, Accuracy: 9771/10000 (97.71%)\n",
        "\n",
        "loss=0.34595927596092224 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.73it/s]\n",
        "\n",
        "Test set: Average loss: 0.0794, Accuracy: 9744/10000 (97.44%)\n",
        "\n",
        "loss=0.1597621589899063 batch_id=117: 100%|██████████| 118/118 [00:25<00:00,  4.71it/s] \n",
        "\n",
        "Test set: Average loss: 0.0798, Accuracy: 9744/10000 (97.44%)\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variation 4 - Combination with Random Application:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "train_transforms = A.Compose([\n",
        "    A.OneOf([\n",
        "        A.ShiftScaleRotate(\n",
        "            shift_limit=0.0625,\n",
        "            scale_limit=0.1,\n",
        "            rotate_limit=15,\n",
        "            p=0.8\n",
        "        ),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.8),\n",
        "        A.ElasticTransform(\n",
        "            alpha=1.0,\n",
        "            sigma=10.0,\n",
        "            alpha_affine=None,\n",
        "            p=0.8\n",
        "        ),\n",
        "    ], p=0.7),\n",
        "    \n",
        "    A.OneOf([\n",
        "        A.GaussNoise(var_limit=(5.0, 30.0), p=0.8),\n",
        "        A.Blur(blur_limit=3, p=0.8),\n",
        "        A.RandomBrightnessContrast(p=0.8),\n",
        "    ], p=0.5),\n",
        "    \n",
        "    A.CoarseDropout(\n",
        "        max_holes=2,\n",
        "        max_height=8,\n",
        "        max_width=8,\n",
        "        min_holes=1,\n",
        "        fill_value=0,\n",
        "        p=0.3\n",
        "    ),\n",
        "    \n",
        "    A.Normalize(mean=[0.1307], std=[0.3081]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "loss=0.47459304332733154 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.83it/s]\n",
        "\n",
        "Test set: Average loss: 0.1772, Accuracy: 9486/10000 (94.86%)\n",
        "\n",
        "loss=0.21334141492843628 batch_id=117: 100%|██████████| 118/118 [00:23<00:00,  4.95it/s]\n",
        "\n",
        "Test set: Average loss: 0.1270, Accuracy: 9609/10000 (96.09%)\n",
        "\n",
        "loss=0.2684533894062042 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.85it/s] \n",
        "\n",
        "Test set: Average loss: 0.1076, Accuracy: 9678/10000 (96.78%)\n",
        "\n",
        "loss=0.400796502828598 batch_id=117: 100%|██████████| 118/118 [00:23<00:00,  4.94it/s]  \n",
        "\n",
        "Test set: Average loss: 0.0978, Accuracy: 9715/10000 (97.15%)\n",
        "\n",
        "loss=0.44975733757019043 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.92it/s]\n",
        "\n",
        "Test set: Average loss: 0.0895, Accuracy: 9726/10000 (97.26%)\n",
        "\n",
        "loss=0.36491188406944275 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.81it/s]\n",
        "\n",
        "Test set: Average loss: 0.0847, Accuracy: 9734/10000 (97.34%)\n",
        "\n",
        "loss=0.1452285796403885 batch_id=117: 100%|██████████| 118/118 [00:23<00:00,  4.94it/s] \n",
        "\n",
        "Test set: Average loss: 0.0827, Accuracy: 9737/10000 (97.37%)\n",
        "\n",
        "loss=0.08702707290649414 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.90it/s]\n",
        "\n",
        "Test set: Average loss: 0.0806, Accuracy: 9744/10000 (97.44%)\n",
        "\n",
        "loss=0.22423332929611206 batch_id=117: 100%|██████████| 118/118 [00:23<00:00,  4.94it/s]\n",
        "\n",
        "Test set: Average loss: 0.0802, Accuracy: 9757/10000 (97.57%)\n",
        "\n",
        "loss=0.17687933146953583 batch_id=117: 100%|██████████| 118/118 [00:23<00:00,  4.95it/s]\n",
        "\n",
        "Test set: Average loss: 0.0764, Accuracy: 9767/10000 (97.67%)\n",
        "\n",
        "loss=0.16285346448421478 batch_id=117: 100%|██████████| 118/118 [00:24<00:00,  4.84it/s]\n",
        "\n",
        "Test set: Average loss: 0.0748, Accuracy: 9765/10000 (97.65%)\n",
        "\n",
        "loss=0.2593475878238678 batch_id=117: 100%|██████████| 118/118 [00:23<00:00,  4.93it/s] \n",
        "\n",
        "Test set: Average loss: 0.0729, Accuracy: 9763/10000 (97.63%)\n",
        "\n",
        "loss=0.19869744777679443 batch_id=117: 100%|██████████| 118/118 [02:43<00:00,  1.39s/it]\n",
        "\n",
        "Test set: Average loss: 0.0721, Accuracy: 9767/10000 (97.67%)\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variation 5 - Minimal but Targeted Augmentations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.0625,\n",
        "        scale_limit=0.1,\n",
        "        rotate_limit=15,\n",
        "        p=0.9,                # Very high probability\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    \n",
        "    A.OneOf([\n",
        "        A.GaussNoise(var_limit=(5.0, 20.0), p=1.0),\n",
        "        A.Blur(blur_limit=3, p=1.0),\n",
        "    ], p=0.3),\n",
        "    \n",
        "    A.CoarseDropout(\n",
        "        max_holes=1,          # Just one hole\n",
        "        max_height=10,        # But potentially larger\n",
        "        max_width=10,\n",
        "        min_holes=1,\n",
        "        fill_value=0,\n",
        "        p=0.25\n",
        "    ),\n",
        "    \n",
        "    A.Normalize(mean=[0.1307], std=[0.3081]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "loss=0.5514877438545227 batch_id=117: 100%|██████████| 118/118 [00:17<00:00,  6.79it/s] \n",
        "\n",
        "Test set: Average loss: 0.1976, Accuracy: 9433/10000 (94.33%)\n",
        "\n",
        "loss=0.1490059643983841 batch_id=117: 100%|██████████| 118/118 [00:17<00:00,  6.90it/s] \n",
        "\n",
        "Test set: Average loss: 0.1270, Accuracy: 9632/10000 (96.32%)\n",
        "\n",
        "loss=0.3203728497028351 batch_id=117: 100%|██████████| 118/118 [00:17<00:00,  6.89it/s] \n",
        "\n",
        "Test set: Average loss: 0.1035, Accuracy: 9678/10000 (96.78%)\n",
        "\n",
        "loss=0.40590357780456543 batch_id=117: 100%|██████████| 118/118 [00:16<00:00,  7.03it/s]\n",
        "\n",
        "Test set: Average loss: 0.0958, Accuracy: 9716/10000 (97.16%)\n",
        "\n",
        "loss=0.4559806287288666 batch_id=117: 100%|██████████| 118/118 [00:16<00:00,  7.10it/s] \n",
        "\n",
        "Test set: Average loss: 0.0871, Accuracy: 9723/10000 (97.23%)\n",
        "\n",
        "loss=0.2535381317138672 batch_id=117: 100%|██████████| 118/118 [00:16<00:00,  6.97it/s] \n",
        "\n",
        "Test set: Average loss: 0.0924, Accuracy: 9729/10000 (97.29%)\n",
        "\n",
        "loss=0.282307893037796 batch_id=117: 100%|██████████| 118/118 [00:16<00:00,  6.99it/s]  \n",
        "\n",
        "Test set: Average loss: 0.0892, Accuracy: 9732/10000 (97.32%)\n",
        "\n",
        "loss=0.16792957484722137 batch_id=117: 100%|██████████| 118/118 [00:17<00:00,  6.82it/s]\n",
        "\n",
        "Test set: Average loss: 0.0811, Accuracy: 9764/10000 (97.64%)\n",
        "\n",
        "loss=0.2787671387195587 batch_id=117: 100%|██████████| 118/118 [00:17<00:00,  6.72it/s] \n",
        "\n",
        "Test set: Average loss: 0.0829, Accuracy: 9743/10000 (97.43%)\n",
        "\n",
        "loss=0.2796783149242401 batch_id=117: 100%|██████████| 118/118 [00:17<00:00,  6.73it/s] \n",
        "\n",
        "Test set: Average loss: 0.0750, Accuracy: 9747/10000 (97.47%)\n",
        "\n",
        "loss=0.180215522646904 batch_id=117: 100%|██████████| 118/118 [00:17<00:00,  6.80it/s]  \n",
        "\n",
        "Test set: Average loss: 0.0726, Accuracy: 9780/10000 (97.80%)\n",
        "\n",
        "loss=0.23531754314899445 batch_id=117: 100%|██████████| 118/118 [00:16<00:00,  6.95it/s]\n",
        "\n",
        "Test set: Average loss: 0.0690, Accuracy: 9795/10000 (97.95%)\n",
        "\n",
        "loss=0.1926894187927246 batch_id=117: 100%|██████████| 118/118 [00:17<00:00,  6.89it/s] \n",
        "\n",
        "Test set: Average loss: 0.0724, Accuracy: 9776/10000 (97.76%)\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
