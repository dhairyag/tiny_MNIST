{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, 3, padding=1),  # 1*3*3*4 + 4 = 40 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(4),              # 8 params\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, 3, padding=1),  # 4*3*3*8 + 8 = 296 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),              # 16 params\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        \n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(8, 12, 3, padding=1), # 8*3*3*12 + 12 = 876 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),             # 24 params\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        \n",
        "        # 12 channels * 3 * 3 = 108 neurons after three max pools (28->14->7->3)\n",
        "        self.fc1 = nn.Linear(12 * 3 * 3, 10)  # 108*10 + 10 = 1090 params\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, 12 * 3 * 3)  # Flatten\n",
        "        x = F.dropout(x, p=0.1)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 4, 14, 14]            --\n",
              "│    └─Conv2d: 2-1                       [1, 4, 28, 28]            40\n",
              "│    └─ReLU: 2-2                         [1, 4, 28, 28]            --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 4, 28, 28]            8\n",
              "│    └─MaxPool2d: 2-4                    [1, 4, 14, 14]            --\n",
              "├─Sequential: 1-2                        [1, 8, 7, 7]              --\n",
              "│    └─Conv2d: 2-5                       [1, 8, 14, 14]            296\n",
              "│    └─ReLU: 2-6                         [1, 8, 14, 14]            --\n",
              "│    └─BatchNorm2d: 2-7                  [1, 8, 14, 14]            16\n",
              "│    └─MaxPool2d: 2-8                    [1, 8, 7, 7]              --\n",
              "│    └─Dropout: 2-9                      [1, 8, 7, 7]              --\n",
              "├─Sequential: 1-3                        [1, 12, 3, 3]             --\n",
              "│    └─Conv2d: 2-10                      [1, 12, 7, 7]             876\n",
              "│    └─ReLU: 2-11                        [1, 12, 7, 7]             --\n",
              "│    └─BatchNorm2d: 2-12                 [1, 12, 7, 7]             24\n",
              "│    └─MaxPool2d: 2-13                   [1, 12, 3, 3]             --\n",
              "│    └─Dropout: 2-14                     [1, 12, 3, 3]             --\n",
              "├─Linear: 1-4                            [1, 10]                   1,090\n",
              "==========================================================================================\n",
              "Total params: 2,350\n",
              "Trainable params: 2,350\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.08\n",
              "Params size (MB): 0.01\n",
              "Estimated Total Size (MB): 0.10\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "# Create a dummy input tensor on the correct device\n",
        "summary(model, input_size=(1, 1, 28, 28), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1456)\n",
        "batch_size = 512\n",
        "\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True} if device.type in [\"cuda\", \"mps\"] else {}\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=True, download=True,\n",
        "#                     transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "# Define the augmentation pipeline\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.0625,\n",
        "        scale_limit=0.1,\n",
        "        rotate_limit=15,\n",
        "        p=0.7,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.3),\n",
        "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
        "    A.Perspective(scale=(0.05, 0.1), p=0.3, keep_size=True, pad_mode=cv2.BORDER_CONSTANT, pad_val=0),\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Custom Dataset class to work with Albumentations\n",
        "class MNISTAlbumentations(datasets.MNIST):\n",
        "    def __init__(self, root, train=True, download=True, transform=None):\n",
        "        super().__init__(root, train=train, download=download, transform=None)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx], self.targets[idx]\n",
        "        \n",
        "        # Convert to numpy array and add channel dimension\n",
        "        img = np.array(img)\n",
        "        img = np.expand_dims(img, axis=-1)  # Add channel dimension for Albumentations\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=img)\n",
        "            img = transformed[\"image\"]\n",
        "            \n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Update the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=True, download=True, transform=train_transforms),\n",
        "    batch_size=batch_size, shuffle=True, \n",
        "    **kwargs)\n",
        "\n",
        "# Test transforms (only normalization, no augmentation)\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=False, transform=test_transforms),\n",
        "    batch_size=batch_size, shuffle=True,  \n",
        "    **kwargs)\n",
        "\n",
        "# Optional: Visualization function to check augmentations\n",
        "def visualize_augmentations(dataset, idx=0, samples=5):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(samples):\n",
        "        data = dataset[idx][0]\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            data = data.numpy()\n",
        "        if data.shape[0] == 1:  # If channels first, move to last\n",
        "            data = np.transpose(data, (1, 2, 0))\n",
        "        plt.subplot(1, samples, i + 1)\n",
        "        plt.imshow(data.squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in train dataset: 60000\n",
            "Number of samples in test dataset: 10000\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to visualize augmentations\n",
        "visualize_augmentations(train_loader.dataset)\n",
        "\n",
        "# # print number of samples in train and test dataset\n",
        "print(f\"Number of samples in train dataset: {len(train_loader.dataset)}\")\n",
        "print(f\"Number of samples in test dataset: {len(test_loader.dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.6400654911994934 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.3536, Accuracy: 9020/10000 (90.20%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.3523024022579193 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.04it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1885, Accuracy: 9451/10000 (94.51%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.392343670129776 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.97it/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1460, Accuracy: 9567/10000 (95.67%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.36068496108055115 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1240, Accuracy: 9633/10000 (96.33%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.3247279226779938 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.99it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1084, Accuracy: 9649/10000 (96.49%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.3495262563228607 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.92it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0975, Accuracy: 9692/10000 (96.92%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.20154260098934174 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0896, Accuracy: 9719/10000 (97.19%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.15310798585414886 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0798, Accuracy: 9760/10000 (97.60%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.34668266773223877 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0812, Accuracy: 9733/10000 (97.33%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "# scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "#     optimizer, \n",
        "#     max_lr=0.1,\n",
        "#     epochs=10,\n",
        "#     steps_per_epoch=len(train_loader)\n",
        "# )\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
