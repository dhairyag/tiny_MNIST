{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, 3, padding=1),  # 1*3*3*4 + 4 = 40 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(4),              # 8 params\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, 3, padding=1),  # 4*3*3*8 + 8 = 296 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),              # 16 params\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        \n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(8, 12, 3, padding=1), # 8*3*3*12 + 12 = 876 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),             # 24 params\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        \n",
        "        # 12 channels * 3 * 3 = 108 neurons after three max pools (28->14->7->3)\n",
        "        self.fc1 = nn.Linear(12 * 3 * 3, 10)  # 108*10 + 10 = 1090 params\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, 12 * 3 * 3)  # Flatten\n",
        "        x = F.dropout(x, p=0.1)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 4, 14, 14]            --\n",
              "│    └─Conv2d: 2-1                       [1, 4, 28, 28]            40\n",
              "│    └─ReLU: 2-2                         [1, 4, 28, 28]            --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 4, 28, 28]            8\n",
              "│    └─MaxPool2d: 2-4                    [1, 4, 14, 14]            --\n",
              "├─Sequential: 1-2                        [1, 8, 7, 7]              --\n",
              "│    └─Conv2d: 2-5                       [1, 8, 14, 14]            296\n",
              "│    └─ReLU: 2-6                         [1, 8, 14, 14]            --\n",
              "│    └─BatchNorm2d: 2-7                  [1, 8, 14, 14]            16\n",
              "│    └─MaxPool2d: 2-8                    [1, 8, 7, 7]              --\n",
              "│    └─Dropout: 2-9                      [1, 8, 7, 7]              --\n",
              "├─Sequential: 1-3                        [1, 12, 3, 3]             --\n",
              "│    └─Conv2d: 2-10                      [1, 12, 7, 7]             876\n",
              "│    └─ReLU: 2-11                        [1, 12, 7, 7]             --\n",
              "│    └─BatchNorm2d: 2-12                 [1, 12, 7, 7]             24\n",
              "│    └─MaxPool2d: 2-13                   [1, 12, 3, 3]             --\n",
              "│    └─Dropout: 2-14                     [1, 12, 3, 3]             --\n",
              "├─Linear: 1-4                            [1, 10]                   1,090\n",
              "==========================================================================================\n",
              "Total params: 2,350\n",
              "Trainable params: 2,350\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.08\n",
              "Params size (MB): 0.01\n",
              "Estimated Total Size (MB): 0.10\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "# Create a dummy input tensor on the correct device\n",
        "summary(model, input_size=(1, 1, 28, 28), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1456)\n",
        "batch_size = 512\n",
        "\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True} if device.type in [\"cuda\", \"mps\"] else {}\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=True, download=True,\n",
        "#                     transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "# Define the augmentation pipeline\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.0625,\n",
        "        scale_limit=0.1,\n",
        "        rotate_limit=15,\n",
        "        p=0.7,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.3),\n",
        "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
        "    A.Perspective(scale=(0.05, 0.1), p=0.3, keep_size=True, pad_mode=cv2.BORDER_CONSTANT, pad_val=0),\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Custom Dataset class to work with Albumentations\n",
        "class MNISTAlbumentations(datasets.MNIST):\n",
        "    def __init__(self, root, train=True, download=True, transform=None):\n",
        "        super().__init__(root, train=train, download=download, transform=None)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx], self.targets[idx]\n",
        "        \n",
        "        # Convert to numpy array and add channel dimension\n",
        "        img = np.array(img)\n",
        "        img = np.expand_dims(img, axis=-1)  # Add channel dimension for Albumentations\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=img)\n",
        "            img = transformed[\"image\"]\n",
        "            \n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Update the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=True, download=True, transform=train_transforms),\n",
        "    batch_size=batch_size, shuffle=True, \n",
        "    **kwargs)\n",
        "\n",
        "# Test transforms (only normalization, no augmentation)\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=False, transform=test_transforms),\n",
        "    batch_size=batch_size, shuffle=True,  \n",
        "    **kwargs)\n",
        "\n",
        "# Optional: Visualization function to check augmentations\n",
        "def visualize_augmentations(dataset, idx=0, samples=5):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(samples):\n",
        "        data = dataset[idx][0]\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            data = data.numpy()\n",
        "        if data.shape[0] == 1:  # If channels first, move to last\n",
        "            data = np.transpose(data, (1, 2, 0))\n",
        "        plt.subplot(1, samples, i + 1)\n",
        "        plt.imshow(data.squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in train dataset: 60000\n",
            "Number of samples in test dataset: 10000\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to visualize augmentations\n",
        "visualize_augmentations(train_loader.dataset)\n",
        "\n",
        "# # print number of samples in train and test dataset\n",
        "print(f\"Number of samples in train dataset: {len(train_loader.dataset)}\")\n",
        "print(f\"Number of samples in test dataset: {len(test_loader.dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.5893550515174866 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.66it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.2394, Accuracy: 9272/10000 (92.72%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.20741552114486694 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1389, Accuracy: 9575/10000 (95.75%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.28161704540252686 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1092, Accuracy: 9650/10000 (96.50%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.3971775770187378 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.95it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0933, Accuracy: 9716/10000 (97.16%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.3540845811367035 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.01it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0866, Accuracy: 9735/10000 (97.35%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.2576209306716919 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.90it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0791, Accuracy: 9744/10000 (97.44%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.2668510973453522 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.96it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0778, Accuracy: 9751/10000 (97.51%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.09346262365579605 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0677, Accuracy: 9785/10000 (97.85%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.21802158653736115 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0676, Accuracy: 9785/10000 (97.85%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, \n",
        "    max_lr=0.1,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=len(train_loader)\n",
        ")\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
