{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.Conv2d(8, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.15)  # Reduced dropout\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.15)  # Reduced dropout\n",
        "        )\n",
        "        \n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 16, 3, padding=1),  # Added intermediate channels\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 10, 1),  # 1x1 conv to reduce channels to num_classes\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 16, 14, 14]           --\n",
              "│    └─Conv2d: 2-1                       [1, 8, 28, 28]            80\n",
              "│    └─ReLU: 2-2                         [1, 8, 28, 28]            --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 8, 28, 28]            16\n",
              "│    └─Conv2d: 2-4                       [1, 16, 28, 28]           1,168\n",
              "│    └─ReLU: 2-5                         [1, 16, 28, 28]           --\n",
              "│    └─BatchNorm2d: 2-6                  [1, 16, 28, 28]           32\n",
              "│    └─MaxPool2d: 2-7                    [1, 16, 14, 14]           --\n",
              "│    └─Dropout: 2-8                      [1, 16, 14, 14]           --\n",
              "├─Sequential: 1-2                        [1, 32, 7, 7]             --\n",
              "│    └─Conv2d: 2-9                       [1, 16, 14, 14]           2,320\n",
              "│    └─ReLU: 2-10                        [1, 16, 14, 14]           --\n",
              "│    └─BatchNorm2d: 2-11                 [1, 16, 14, 14]           32\n",
              "│    └─Conv2d: 2-12                      [1, 32, 14, 14]           4,640\n",
              "│    └─ReLU: 2-13                        [1, 32, 14, 14]           --\n",
              "│    └─BatchNorm2d: 2-14                 [1, 32, 14, 14]           64\n",
              "│    └─MaxPool2d: 2-15                   [1, 32, 7, 7]             --\n",
              "│    └─Dropout: 2-16                     [1, 32, 7, 7]             --\n",
              "├─Sequential: 1-3                        [1, 10, 3, 3]             --\n",
              "│    └─Conv2d: 2-17                      [1, 16, 7, 7]             4,624\n",
              "│    └─ReLU: 2-18                        [1, 16, 7, 7]             --\n",
              "│    └─BatchNorm2d: 2-19                 [1, 16, 7, 7]             32\n",
              "│    └─Conv2d: 2-20                      [1, 10, 7, 7]             170\n",
              "│    └─ReLU: 2-21                        [1, 10, 7, 7]             --\n",
              "│    └─BatchNorm2d: 2-22                 [1, 10, 7, 7]             20\n",
              "│    └─MaxPool2d: 2-23                   [1, 10, 3, 3]             --\n",
              "==========================================================================================\n",
              "Total params: 13,198\n",
              "Trainable params: 13,198\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 2.58\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.47\n",
              "Params size (MB): 0.05\n",
              "Estimated Total Size (MB): 0.53\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "# Create a dummy input tensor on the correct device\n",
        "summary(model, input_size=(1, 1, 28, 28), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1456)\n",
        "batch_size = 512\n",
        "\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True} if device.type in [\"cuda\", \"mps\"] else {}\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=True, download=True,\n",
        "#                     transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "# Define the augmentation pipeline\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.0625,\n",
        "        scale_limit=0.1,\n",
        "        rotate_limit=15,\n",
        "        p=0.7,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.3),\n",
        "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
        "    A.Perspective(scale=(0.05, 0.1), p=0.3, keep_size=True, pad_mode=cv2.BORDER_CONSTANT, pad_val=0),\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Custom Dataset class to work with Albumentations\n",
        "class MNISTAlbumentations(datasets.MNIST):\n",
        "    def __init__(self, root, train=True, download=True, transform=None):\n",
        "        super().__init__(root, train=train, download=download, transform=None)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx], self.targets[idx]\n",
        "        \n",
        "        # Convert to numpy array and add channel dimension\n",
        "        img = np.array(img)\n",
        "        img = np.expand_dims(img, axis=-1)  # Add channel dimension for Albumentations\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=img)\n",
        "            img = transformed[\"image\"]\n",
        "            \n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Update the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=True, download=True, transform=train_transforms),\n",
        "    batch_size=batch_size, shuffle=True, \n",
        "    **kwargs)\n",
        "\n",
        "# Test transforms (only normalization, no augmentation)\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=False, transform=test_transforms),\n",
        "    batch_size=batch_size, shuffle=True,  \n",
        "    **kwargs)\n",
        "\n",
        "# Optional: Visualization function to check augmentations\n",
        "def visualize_augmentations(dataset, idx=0, samples=5):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(samples):\n",
        "        data = dataset[idx][0]\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            data = data.numpy()\n",
        "        if data.shape[0] == 1:  # If channels first, move to last\n",
        "            data = np.transpose(data, (1, 2, 0))\n",
        "        plt.subplot(1, samples, i + 1)\n",
        "        plt.imshow(data.squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in train dataset: 60000\n",
            "Number of samples in test dataset: 10000\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to visualize augmentations\n",
        "visualize_augmentations(train_loader.dataset)\n",
        "\n",
        "# # print number of samples in train and test dataset\n",
        "print(f\"Number of samples in train dataset: {len(train_loader.dataset)}\")\n",
        "print(f\"Number of samples in test dataset: {len(test_loader.dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.347416490316391 batch_id=117: 100%|██████████| 118/118 [00:13<00:00,  8.88it/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1701, Accuracy: 9620/10000 (96.20%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.2271554321050644 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.28it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0917, Accuracy: 9759/10000 (97.59%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.2413731813430786 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.20it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0726, Accuracy: 9803/10000 (98.03%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.08989568799734116 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0607, Accuracy: 9845/10000 (98.45%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.08049821853637695 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0498, Accuracy: 9861/10000 (98.61%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.10398530960083008 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0427, Accuracy: 9874/10000 (98.74%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.08669831603765488 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0412, Accuracy: 9883/10000 (98.83%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.12325470894575119 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0396, Accuracy: 9887/10000 (98.87%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.21702559292316437 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0346, Accuracy: 9904/10000 (99.04%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
