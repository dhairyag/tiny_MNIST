{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.Conv2d(8, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.15)  # Reduced dropout\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.15)  # Reduced dropout\n",
        "        )\n",
        "        \n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 16, 3, padding=1),  # Added intermediate channels\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 10, 1),  # 1x1 conv to reduce channels to num_classes\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 16, 14, 14]           --\n",
              "│    └─Conv2d: 2-1                       [1, 8, 28, 28]            80\n",
              "│    └─ReLU: 2-2                         [1, 8, 28, 28]            --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 8, 28, 28]            16\n",
              "│    └─Conv2d: 2-4                       [1, 16, 28, 28]           1,168\n",
              "│    └─ReLU: 2-5                         [1, 16, 28, 28]           --\n",
              "│    └─BatchNorm2d: 2-6                  [1, 16, 28, 28]           32\n",
              "│    └─MaxPool2d: 2-7                    [1, 16, 14, 14]           --\n",
              "│    └─Dropout: 2-8                      [1, 16, 14, 14]           --\n",
              "├─Sequential: 1-2                        [1, 32, 7, 7]             --\n",
              "│    └─Conv2d: 2-9                       [1, 16, 14, 14]           2,320\n",
              "│    └─ReLU: 2-10                        [1, 16, 14, 14]           --\n",
              "│    └─BatchNorm2d: 2-11                 [1, 16, 14, 14]           32\n",
              "│    └─Conv2d: 2-12                      [1, 32, 14, 14]           4,640\n",
              "│    └─ReLU: 2-13                        [1, 32, 14, 14]           --\n",
              "│    └─BatchNorm2d: 2-14                 [1, 32, 14, 14]           64\n",
              "│    └─MaxPool2d: 2-15                   [1, 32, 7, 7]             --\n",
              "│    └─Dropout: 2-16                     [1, 32, 7, 7]             --\n",
              "├─Sequential: 1-3                        [1, 10, 3, 3]             --\n",
              "│    └─Conv2d: 2-17                      [1, 16, 7, 7]             4,624\n",
              "│    └─ReLU: 2-18                        [1, 16, 7, 7]             --\n",
              "│    └─BatchNorm2d: 2-19                 [1, 16, 7, 7]             32\n",
              "│    └─Conv2d: 2-20                      [1, 10, 7, 7]             170\n",
              "│    └─ReLU: 2-21                        [1, 10, 7, 7]             --\n",
              "│    └─BatchNorm2d: 2-22                 [1, 10, 7, 7]             20\n",
              "│    └─MaxPool2d: 2-23                   [1, 10, 3, 3]             --\n",
              "==========================================================================================\n",
              "Total params: 13,198\n",
              "Trainable params: 13,198\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 2.58\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.47\n",
              "Params size (MB): 0.05\n",
              "Estimated Total Size (MB): 0.53\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "# Create a dummy input tensor on the correct device\n",
        "summary(model, input_size=(1, 1, 28, 28), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1456)\n",
        "batch_size = 512\n",
        "\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True} if device.type in [\"cuda\", \"mps\"] else {}\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=True, download=True,\n",
        "#                     transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "# Define the augmentation pipeline\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.0625,\n",
        "        scale_limit=0.1,\n",
        "        rotate_limit=15,\n",
        "        p=0.7,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
        "    A.Perspective(scale=(0.05, 0.1), p=0.3, keep_size=True, pad_mode=cv2.BORDER_CONSTANT, pad_val=0),\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Custom Dataset class to work with Albumentations\n",
        "class MNISTAlbumentations(datasets.MNIST):\n",
        "    def __init__(self, root, train=True, download=True, transform=None):\n",
        "        super().__init__(root, train=train, download=download, transform=None)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx], self.targets[idx]\n",
        "        \n",
        "        # Convert to numpy array and add channel dimension\n",
        "        img = np.array(img)\n",
        "        img = np.expand_dims(img, axis=-1)  # Add channel dimension for Albumentations\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=img)\n",
        "            img = transformed[\"image\"]\n",
        "            \n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Update the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=True, download=True, transform=train_transforms),\n",
        "    batch_size=batch_size, shuffle=True, \n",
        "    **kwargs)\n",
        "\n",
        "# Test transforms (only normalization, no augmentation)\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=False, transform=test_transforms),\n",
        "    batch_size=batch_size, shuffle=True,  \n",
        "    **kwargs)\n",
        "\n",
        "# Optional: Visualization function to check augmentations\n",
        "def visualize_augmentations(dataset, idx=0, samples=5):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(samples):\n",
        "        data = dataset[idx][0]\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            data = data.numpy()\n",
        "        if data.shape[0] == 1:  # If channels first, move to last\n",
        "            data = np.transpose(data, (1, 2, 0))\n",
        "        plt.subplot(1, samples, i + 1)\n",
        "        plt.imshow(data.squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB7oAAAGGCAYAAADl+o4QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzOUlEQVR4nO3ba7BeZXn4/2sfcw4hIglBTgJiMZyUg1gseEbrmdbWs2OtOoOdTmf0hZ2OHduxdaboKGNfWGltpbRltBYVEVBQFAVqFJEYlDMYTTRADjvJzj48z/N78Zv567/D9JfrMll735vP53W+s1bWXs+97vVcew8NBoNBAAAAAAAAAEAjhuf6BAAAAAAAAAAgw6AbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGiKQTcAAAAAAAAATTHoBgAAAAAAAKApBt0AAAAAAAAANGV0f//h0NDQwTwPAA6ywWDQ2bEqz4zR0f1+JP1/Zmdn001E7fy6vH5Z1Wf0yMhIuqlch16vl25YuIaH879n2e/3D8KZPL6Ftj5E1P5P8/2aAzB/dPkcXLJkSbqZnp5ON9Xn4Pj4eLqpnN98t2jRonRTueaV67137950EzH/91NdWbx4cbqpvrfP1+NEzO93muXLl5e6PXv2pJvK9zhdrnneMwDatr/vGf6iGwAAAAAAAICmGHQDAAAAAAAA0BSDbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTRuf6BAAOtqGhoXQzMjKSbvr9frr5Tbr5rHL9ZmdnD8KZPL7BYJBuxsbG0s3MzEy6qaj8f6pd5X6t3A+9Xi/dRMzvn1PF8HDtdxIr6171mneheh0q92v185RV+RlVu4X4nAHgiamyb+vyOVjZs4yPj6eb6enpdFOxaNGiUjc1NXWAz+TxdbmP72qPODqa/6q28i5d3V9XzPfzq+hqXam8S1ffMyprUfVYAHAgze9dAwAAAAAAAAD8DwbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQlNG5PgGYL4aGhjppVq5cmW4iIg455JB0c+ihh6ab3bt3p5vFixenm9NPPz3dRESsX78+3QwGg3Rz2223pZubbrop3UREbN++vdTNZ71eL90MD+d/96rSRET0+/10MzMzUzpW1tjYWLqpnlvl51RR+TmNjIyUjtXVz6mr/1P1/1N5PnWl8vkbHa1tWSvHqqhc78qzMyJicnKy1AHAQlDZv1ae05V3yIja+XW1f62o7ikr+97KsWZnZ9NN9T2jq3fcyr03Pj6ebqanp9NNRO38Kj/byj6+cpzKtYuo3Q+V+7VynImJiXQTUXvnqvyfAOBA8xfdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAU0bn+gTg/2V4OP/7GOPj4+lmxYoV6WbZsmXp5rTTTks3ERHHHXdculmzZk262bp1a7qpXLvzzjsv3UREnHjiienmoYceSjd33313uuE3MxgM0s3s7GzpWCMjI6Vuvh5nvpuZmensWJVnRuXeq/xsq/drReX/1JWhoaF00+/3S8datGhRupmamiodK2tycrLUVa5fpQEeX+XzVHlmdLlWVvR6vc6OBb+pymew+nmq7Hsr51dppqen082+ffvSTUTtO5nK+VXWyur6VXnP6Or8ulyTK3vlyrWr6PI7ha6ueeWzXj23Lt9XAeBA8hfdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJoyOtcnwOMbGhoqdaOj+R/p2NhYulm+fHm6Wb16dbqJiHjSk56Ubo499th0s27dunSzcuXKdHPqqaemm4ja+c3Ozqabu+66K91U7tfh4drv2WzcuDHd/Pd//3e6uf3229PN3r170w2/MhgMFtyxer1eJw2/0u/3001lDZuZmUk3FSMjI6Wuch9VjlU5TuXzt2jRonQTEbFv375Sl9Xl+lV5flpXOBAqa+WSJUvSzaGHHppuKu8LEbV3hspauWrVqnQzMTGRbn7605+mm4iIc845J91Ufk6V98FLLrkk3bzwhS9MNxERxxxzTLq555570s3NN9+cbh566KF0s1BV1qLKe3FVV/upyp63ovrdVFd75cr5VfdtXV3zyvd6Xd7jFV29oy1evDjddPW+UFW5H7q8x6vvqwBwIPmLbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNGZ3rE3giGBoaSjfLli0rHWvNmjXp5sgjj0w3xx13XLo55ZRT0k1ExEknnZRuzj777HRz2GGHpZvBYJBuKvdD1Te/+c108+CDD6abX/7yl+lm9+7d6SYiYvPmzenm/vvvTzdbtmxJNzMzM+mGXxkZGemkiYiYnp5ON119divrStWKFSvSTeWa9/v9dDMxMZFuIiLGxsbSzdKlS9NN5ed0/PHHp5tjjjkm3UREjI+Pp5s77rijk+NU9h179uxJNxERDz30ULqpPGd6vV66GR6u/b5p5VhwIKxevTrdvPe97003r3vd69JNdV85Opp/Ha7sByrr3sqVK9NNl2ZnZ9NNZU2u7Nkq91BExOGHH55uNm3alG727t2bbirXbqHqcq9cUVlXKs/2ynEq76tdXu/K+lp5z6i+Q1Z+TpVjLV68ON1U1pV169alm4iICy64IN2sXbs23VS+m6q8M7z73e9ONxERz372s9PN1772tXTzgQ98IN3cd9996Sai9l48NTVVOhYsdJX1/5BDDjkIZ3JgvOc97yl1lXWlMgu6+OKL080ll1ySbl7/+tenm4iIffv2pZsPf/jD6eaDH/xgulko/EU3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKaMzvUJPBGMjuYv87HHHls61u/+7u+mm+c///np5qijjko3a9asSTcREcuXL0834+Pj6WZycjLd7N69O91Uzi0iYmxsLN1873vfSzfXXHNNuvnZz36WbirXOyJi37596WZ6ejrd9Pv9dEP3Kj/biIihoaF0MxgMOjlOZc074YQT0k1EbS0/4ogj0k3lmfaUpzwl3UREPO1pT0s3q1evTjfbt29PN5X7dcWKFekmImJ2djbdVNb/E088Md28+MUvTjfDw7Xfzfz3f//3dPO3f/u36Wbz5s3pBlqzZ8+edFNZiw4//PB089SnPjXdzHc7d+7s7FgrV65MN71eL918/OMfTzcVV155Zamr7P/vueeedLNhw4Z0w69U3otnZmbSzcjISLqJqL+fZFXeM+a7ys920aJF6aay5kXU3jOWLl2abp773Oemm6OPPjrdVK53RG3/X7kOlf31xMREujnvvPPSTUTEz3/+83Tzwx/+MN3s3bs33VTfnSrHqt5H8Osqa1jl+/XnPOc56aa6RqxatSrdXHTRRaVjLTSV9f/SSy9NN695zWvSTeU5ExFxxx13pJubbrqpdKwnKn/RDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGiKQTcAAAAAAAAATTHoBgAAAAAAAKApo3N9Ak8Eo6P5y7x27drSsc4888x0c+6556abpUuXppuhoaF0U+16vV66ueuuu9LNHXfckW6WLFmSbiJq98TGjRvTzYMPPphuHnvssXRTNRgMOmnoXuVzW1W5Jypr0fBw/vfJKse56KKL0k1ExJ/8yZ+kmxUrVqSbrq53VeXn1O/3O2mq1+ErX/lKuqk828fHx9PNhg0b0s2WLVvSTUTEl770pXTzi1/8onSsrMr9AHNp37596eYLX/hCulm1alW6qe4h3vrWt6abyvlt27Yt3fzjP/5juqmsyRG1fcSjjz6abj71qU+lm8qzadGiRekmonYfTU5OppuJiYl0w6/Mzs6mm7GxsXQzMzOTbiK628NWvmeanp5ON9X/T+Wze8opp6SbZzzjGenmrLPOSjcRESeffHK6OfTQQ9PN+vXr001F9R6vrJWbN29ONzfccEO6qTybrrrqqnQTEXH//fenm5/85Cfp5pFHHkk3XX4HVlmTWbhOP/30UnfjjTemm0MOOaR0LLpV+d7jL/7iL9LN7t27080VV1yRbqrfTW3fvj3dVJ4ZT2T+ohsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGjK6FyfwBPBzMxMutm6dWvpWHfccUe6Wbx4cbpZtmxZujn++OPTTUTEkUcemW4efvjhdPOxj30s3dx2223pZunSpekmIuKkk05KN3fddVe62bNnT7rp9/vpBubS0NBQuhkMBp00s7Oz6eYXv/hFuomIuO+++9LNUUcdlW6e/OQnp5ter5duImrr0d13351uduzYkW6OO+64dLNixYp0ExFxxRVXpJtNmzalm/Hx8XQzOTmZbirPpoiIhx56KN2Mjua3x5XP+sjISLqJqH82YC5s2LAh3VQ+t8PDtd/frryfXHjhhenmM5/5TLr5y7/8y3RT9dnPfjbdnHnmmelm3759nTQsbJX36b179x6EM3l8lT1BRWU/VV0rKw455JB0c/HFF6eb173udemmstermpqaSjeVe6jyHVh1f33yySenm127dqWbyy67LN1MT0+nm+r3WZX/U8XY2Fi6qb5ndHW/snBV1qKIiEcffTTdVJ4zC1FlNlH5Put5z3teuomorcuXX3556Vg8sfmLbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNGZ3rE3gi6PV66WbLli2lY914443p5sc//nG6Wb58ebq54IIL0k1ExAte8IJ0c9ttt6Wb22+/Pd088MAD6WZoaCjdRET87Gc/SzeTk5PpZmpqKt1Aa4aH87/n1e/3O2kqn9trr7023UREDAaDUpf1lre8Jd2cffbZpWM9/PDD6eYDH/hAurn77rvTzRlnnJFuLrroonQTEXHDDTekm23btpWOlVX5/FXv1UpX+dxWVPaHEbV9RFefdTgQKmvR2NhY6Vhbt25NN5XndOXdbmZmJt1UP+u33nprJw0cCNPT0+mm8tmovrdXjjUyMpJuKvuI8fHxdFP9fmBiYiLdfO9730s3J510UroZHa19FfrUpz413axYsSLdbN++Pd185CMfSTf33ntvuomIOO2009JN5ee0Z8+edLN79+50U91DVO6jyrpS+axX32cq72mV9YuF67HHHit173vf+9LNy1/+8nRT+e7/0ksvTTdVP/jBD9LNi170onRTWV+f8YxnpJuIiD/90z8tdZDlL7oBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGiKQTcAAAAAAAAATTHoBgAAAAAAAKApBt0AAAAAAAAANGV0rk/giWAwGKSbnTt3lo71ox/9KN3cd9996WbVqlXp5ogjjkg3ERHnnHNOulm8eHEnzcjISLqZmppKNxER27ZtK3UwF4aH879H1e/3D8KZPL5er9fZsbpw7733lroHH3ww3VR+TitWrEg3xx13XLqJiLj88svTzY033phuduzYkW4q1/uBBx5INxG1Z8bQ0FC6qexxKvdQ5dyqulqLKutkRO38Rkdt+VnYKmtRRMTnP//5dHPBBRekmzPPPDPdrF69Ot08+uij6QZaMzMz08lxxsfHS131fb8LXZ7bxMREurn66qvTzWOPPZZu9u7dm24iIl7ykpekm7e85S3p5vrrr083n/3sZ9PN1q1b001ExC233JJuTjjhhHRT/TllVdeUyl6+sq5MT0+nm+ref3Z2Nt1U92Dw66666qp0U/kep/JsOu2009JNRMQf/dEfpZtLLrkk3ezZsyfdVFRmThER73znOw/wmcDj8xfdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJoyOtcnwOObnZ0tdTt37kw3u3btSjdTU1Pp5u677043ERE///nP081JJ52Ubk455ZR088gjj6SbyvWOiNizZ0+6mZ6eTjeDwSDdwP9UuY9GR/OPpOpaOTQ0lG4W4mejev2yZmZm0s34+HjpWM9+9rPTzYc//OF00+v10k3lGX3TTTelm6qRkZF0U7mHKsfp9/vpJqL2WR8ezv8eaOV+qK4pletXOT9oSfV59v3vfz/dXHvttenmggsuSDd/+Id/mG5uuOGGdBMR8fDDD6ebvXv3lo4Fc6HybK/sXyMixsbGOjlWl+9OXXnggQfSTWX9qu6LKnuwCy+8sJPjVL6jq9qxY0e62bBhw4E/kcdR+axX3zMqXaWpvM9UmqqF+D0Jbah+v55V+R6n6o//+I/TzZVXXpluqusezGf+ohsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGjK0GAwGOzXPxwaOtjnQkNGRkbSzRFHHFE61hve8IZ08/a3vz3dfPe73003N910U7rZsmVLuomIuOeeezo51t69e9NNr9dLN3RvP5f7A6KyRvT7/YNwJo9veDj/e15dnt98Vrl2ixcvTjdf/vKX001ExDnnnJNuXvrSl6abyvo/Pj6ebmZmZtJNRLef96wuP3+VtairZ1p1b93Vz7bLe8h7BnOlskZccMEF6eav/uqv0s1hhx2WbjZu3JhuIiI+8YlPpJtvf/vb6WZ6ejrd0IYunxld7acWLVqUbiJq9/l83rd1aWxsLN1U98oVlfeM97///enmWc96Vrp5xzvekW6+8Y1vpJuI2l658rzt6mc7398zKu9O1b115VpU3vUr3ztWec/gN7Vs2bJS96UvfSndnH/++emm8n3W9ddfn25gruzvPtlfdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGiKQTcAAAAAAAAATTHoBgAAAAAAAKApBt0AAAAAAAAANMWgGwAAAAAAAICmGHQDAAAAAAAA0BSDbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoytBgMBjs1z8cGjrY58ICNzY2VuqOOeaYdPPBD34w3Zx11lnpZufOnenml7/8ZbqJiPja176Wbr71rW+lm3vvvTfd7Nq1K930+/10w29mP5f7A6LyzBgezv/ulfvo/6pcu4j5ff3OPvvsUnfdddelmw0bNqSbz3/+8+nmzjvvTDc333xzuomo3xNZlXuosh+YmZlJNwtVZX2tNL1eL91Uec+gJStXrkw3r371q9PNu971rnRz5plnppuIiKuvvjrdfPSjH003t956a7rpci2ibr6/Z1RUv79YaHuW6vWu7EUrn/eu3jurx3rFK16Rbv78z/883dx3333p5utf/3q6iYi4//770803vvGNdNPVZ6mr96aI2rvT6OhoupmdnU03VZXz63Kd9J7BXDn++OPTzfe///10s2PHjnRTWf8r35tFRPz93/99uulyX8n8t7/3g7/oBgAAAAAAAKApBt0AAAAAAAAANMWgGwAAAAAAAICmGHQDAAAAAAAA0BSDbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANCU0bk+AZ44ZmZmSt3mzZvTzWWXXZZuhofzv/fxzGc+M92ceOKJ6SYiYs2aNenm8MMPTzdf+cpX0s2dd96Zbnbu3JluIiL6/X6pY/6r/GzHx8dLx5qenu7kWJXjVFQ/FyMjI+mmslZW1v8f//jH6SYi4pJLLkk3f/Znf5ZuTjrppHRzyy23pJvZ2dl0ExFxxx13pJvKz6ly71X3AxWV+7Wr50zl3Ko8O+HA2bVrV7r5r//6r3QzNTWVbt7ylrekm4iIV73qVemmsq68//3vTzf33ntvuoH/aWxsLN30er2DcCZza8mSJelmcnKydKyu9h6DwSDddPmzve6669LN05/+9HTzB3/wB+nm5JNPTjcRETt27Eg3hx12WLq59tpr083u3bvTTfV9q3LvVVTPD5hb9913X7p529velm4+/elPp5s3v/nNnTQREcuWLUs3n/nMZ9LNli1b0g0Li7/oBgAAAAAAAKApBt0AAAAAAAAANMWgGwAAAAAAAICmGHQDAAAAAAAA0BSDbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANCUocFgMNivfzg0dLDPBR5X5d5bvnx5ujn55JPTzUtf+tJ0c+6556abiIgTTjgh3ezatSvd3HbbbenmP//zP9PNLbfckm4iInbv3l3qiNjP5f6AGB7O/x5Vl+c3n1XWvMr1jqhd836/XzpWVnXfsXbt2nTz1re+Nd28/e1vTzdPetKT0s0Xv/jFdBMR8alPfSrdbNiwId1MT0+nmy6Njo6mm9nZ2YNwJnOr8nnq6rMe4T0DHs+iRYvSzemnn1461ne+85100+v10s2VV16Zbt785jenG7rX5T6+8sxYiPuBxYsXp5t9+/YdhDM5cMbHx9PNzMxMuunyfq3ce2vWrEk3r33ta9PNG97whnQTEXHGGWekmx/84Afp5oorrkg3//Ef/5Futm3blm66VHnXr34/UFn3RkZGOjlOlfcMFrr169enm49+9KPp5gUveEG6qfrkJz+Zbj70oQ+lm5/97Gfphu7t777NX3QDAAAAAAAA0BSDbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaMrQYDAY7Nc/HBo62OcCc2rJkiXp5phjjkk3p512WrqJiHj3u9+dbtavX59utm/fnm7+7d/+Ld3867/+a7qJiHjwwQfTzezsbOlYC81+LvcHhGcGv65yP1Tv17GxsXRz2GGHpZsXvvCF6eZtb3tbujn11FPTTUTEV77ylXTz8Y9/PN1873vfSzeVn1F1Ha/ce/1+v3SshcYzAw6co48+Ot2ccsop6ebwww9PNxERl112WbqprBEbNmxIN+94xzvSzcaNG9MNvxnPjO5V9lMzMzMH4UzaU72HRkZG0k1X30Uceuih6eb8888vHevlL395unn1q1+dbnbs2JFuvvrVr6abiy++ON1E1N4Zunwvns88M2BurVq1Kt284hWvKB3r05/+dLqpfG5vvPHGdPOiF70o3dC9/X1m+ItuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGiKQTcAAAAAAAAATTHoBgAAAAAAAKApBt0AAAAAAAAANMWgGwAAAAAAAICmGHQDAAAAAAAA0BSDbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKaNzfQIwX8zMzKSbRx55JN3cc8896SYiYvfu3elm8eLF6WbNmjXpZtWqVelmdNTyw9wZGRlJN71eL90MD+d/n6zf76eboaGhdBMRMRgMSt18PU5EbS3ftm1burn66qvTzdOe9rR08/znPz/dRERceOGF6ebOO+9MN5s2bUo3k5OT6aaqcu91tT5UjlM9lmcuLal+NiqOPfbYdPPGN74x3Zx11lnpZt26denmyU9+crqJqO1Xtm/fnm6uu+66dPOjH/0o3cD/VLnHu9y/Vo5V2fN2qXLNuzpO9d2pcqzZ2dnSsbImJibSzVVXXVU6VuWd4YQTTkg3559/frpZsWJFurniiivSTUTErbfemm66Wlcq3ylEzP+1EjgwduzYkW4uv/zy0rEuu+yydFP5/uJ3fud30s0FF1yQbr7xjW+kG7rhL7oBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGiKQTcAAAAAAAAATTHoBgAAAAAAAKApBt0AAAAAAAAANGV0rk8A/l+GhobSzdjYWLpZu3ZtunnGM56Rbk488cR0E1E7v9HR/Ed8YmIi3Wzfvj3d7Nq1K91ERPR6vVLHwjQ+Pl7qZmdn001lXZmZmUk3FYPBoJPjRESMjIykm8rntrJ+RUQsX7483axfvz7dVNb/c845J91MTU2lm4iIxYsXp5vKfVT5DE5OTqabLlXu18pepd/vp5uIiOHh/O+penZyIFTWlaVLl6abpz3taenmZS97WbqJiHjd616Xbg4//PB0U3k2VfYd+/btSzcREffcc0+6+fGPf5xuNmzYkG663OOwcFWfuV3pan9d2UNUP4OVa145v8px5vv9UFG5dk9/+tNLx/qt3/qtdFPZD1Te2ffu3Ztutm3blm4iavv/yv+porKmRHhngBadeuqp6eb3fu/30s1ZZ52VbiLq3+1lbdq0Kd1885vfPAhnwlzxF90AAAAAAAAANMWgGwAAAAAAAICmGHQDAAAAAAAA0BSDbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmjI61yfAE8fwcO33KpYvX55ujj766HRz3nnnpZvnPe956ebkk09ONxERRx55ZLqZnJxMN/fdd1+6efDBB9PNxMREuomIGAwGpY75b2hoKN1MT08fhDN5fP1+v5PjjI7mH82zs7OlY1WueaV58pOfnG4qa3JExKtf/ep0s379+nSzcuXKdPOUpzwl3VSfnZs3b043GzduTDc7d+5MN5V7qLr2V45V0eWzyXOQX7ds2bJ088pXvrJ0rFWrVqWbyp78TW96U7qprK8Rtc9TZV3ZtWtXuvn2t7+dbjZs2JBuIiJuvfXWdPOd73wn3WzZsiXdwFyp7sEqer1eulm8eHG62bdvXyfHqR6roqu9XtWSJUvSTeW7n9NOOy3dvOpVr0o3EbV3p+OPPz7dVN6Lt2/fnm6mpqbSTUTEzMxMuhkbG0s3Xb2zR9T2RZX/EzwRnHTSSenmPe95T7p57Wtfm27Wrl2bbrpU2RdV3jO6+p6XbviLbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNGZ3rE6BNIyMj6Wb58uWlY51yyinp5k1velO6edGLXpRu1q1bl24q1y4i4rHHHks33/3ud9PNl7/85XTz7W9/O91MTk6mGxa24eH87171er2DcCZzazAYpJvR0drj/ElPelK6eeYzn5luKmvyc57znHQTEbF69ep0s2TJknRTuV937NiRbjZs2JBuIiJuuummdLNp06bSsbIqz8HZ2dnSsSqfjZmZmdKx5rOhoaG5PoUnnPXr16ebN77xjenmiCOOSDe//du/nW4iIg477LB0s2rVqtKxsqprxPbt29PNtddem26++tWvpps777wz3Tz00EPpJqJ2HWCuVPYRlXeG6v56eno63VT2ldV1L6u6h1i0aFG6mZqaKh2rK5VnWmU/8LKXvSzdvOIVr0g3Rx99dLqJiFi2bFm6qTxnrr766nTzL//yL+mmy2dg5XNb+X6gS/P9cwu/bu3atenm9a9/felY73nPe9LNscceWzrWfFb5TutDH/pQuvniF7+YblhY/EU3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKaMzvUJMPdGR/O3wbp169LNi1/84nQTEfGmN70p3ZxxxhnpZvny5elm79696eauu+5KNxERN998c7q5/vrr0833v//9dLNt27Z00+v10g3tGBkZSTeDweAgnMmBU1krjz766HRTWV8POeSQdBMR8YY3vCHdvOQlL0k3ixYtSjfj4+PpJiJibGws3Tz88MPp5pvf/Ga6+e53v5tubrvttnQTEfGDH/wg3UxPT5eOldXv9zs5TkTEzMxMJ8eprHldPgfn+/q6EL35zW9ON+985zvTzZIlS9LN8HDtd523bt2abrZs2ZJuKue3adOmdBMR8U//9E/pprIuT0xMpJupqal047POE0FXz8+u9kURtb1RV/up6l6qq/OrvGcsXbq0dKzzzz8/3fz+7/9+unn5y1+ebirfZ+3cuTPdRETccsst6eaaa65JN9/61rfSTeX7rMrzll+p7ivh161ZsybdnHzyyenmE5/4RLp5+tOfnm7mu8r7zN/93d+VjvWFL3wh3XT5nRELh6cRAAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQlKHBYDDYr384NHSwz4VfMzo6WupWrlyZbk455ZR0c9FFF6WbF7/4xekmIuLII49MN5Xr98gjj6Sb22+/Pd1cc8016SYi4jvf+U66efjhh9PN7t27083s7Gy6oXv7udwfEGNjY+mm1+ulm9WrV6ebiIgTTjgh3axbty7dVNa98847L90cffTR6SYiYtmyZemm3++nm+Hh/O/V3XvvvekmIuLqq69ONzfccEO6eeCBB9LNT3/603SzZ8+edFNV+TlV9oeVz3rVyMhIuqmcX+U6dLkmV3R5fgvxPWPp0qXp5sQTT0w3a9euTTeV51nVxMREutm8eXO6qezJIyKmpqZKHfD/N9/fMyrnV9lDRNTejSvnN9/3EZV95apVq9JN5Zn23Oc+N91ERLz3ve9NN5X3tH379qWbrVu3pptbb7013UREfO5zn0s3X//619PNrl270k2XKnu9vXv3ppsu98mVdaVyfpXvFKoW4ntGVyrft33yk58sHev0009PN0996lNLx5rPKt/9f+QjH0k31113XbqZnJxMN3Ag7O+zyV90AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGjK0GAwGOzXPxwaOtjn0oTh4fzvBhxxxBHp5vTTT083ERHPetaz0s0ZZ5zRyXEq1yEiYnp6Ot1s3Lgx3Vx33XXp5uabb043d911V7qJiNi2bVu6mZqaSjf7uSTQoC5/tl09M5797GeXuosvvjjdnHvuuemmsu71+/10U1knIyLGx8fTTeU++tznPpduLr/88nQTEfHDH/4w3UxMTKSbmZmZdNPlZ3DRokXppvLMqOyLKvf4yMhIuomI6PV6pY6F+cwA4OBYiM+MLvceY2Nj6aayn6qcW/V6H3LIIenmr//6r9PNhRdemG4OP/zwdBMRsXLlynRT+TnddNNN6eaLX/xiurnqqqvSTUTEww8/nG4q12F0dDTdVNaiyvtMRO19sKKyFs33/9NCfGZ06Zxzzkk373vf+9LN2WefnW6OPPLIdDPf7d27t9Rdeuml6eZv/uZv0s2ePXvSDbRkf58Z/qIbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGiKQTcAAAAAAAAATTHoBgAAAAAAAKApBt0AAAAAAAAANMWgGwAAAAAAAICmGHQDAAAAAAAA0BSDbgAAAAAAAACaYtANAAAAAAAAQFNG5/oEDpSxsbF0s3r16nRzzDHHpJuzzjor3Tz3uc9NNxERp512Wro54ogj0s3y5cvTze7du9NNRMSGDRvSzec+97l0861vfSvdPPjgg+lmcnIy3URE9Pv9UgetGBoaSjfVdWXTpk3pZmpqKt2sW7euk+Pcfvvt6SYiotfrpZsrr7wy3TzyyCPpprpWVq5fVyp7lZmZmdKxuroOXT2bKvdq1fBw/vdAK9dhZGQk3UR0ey0A4Imqsm+LqD2nZ2dn003l3enYY49NN+9617vSTUTEq171qnRz1FFHlY6VVd0n33///enmJz/5Sbr5h3/4h3RzzTXXpJuqwWAwb49T+fxV99aVz+DoaP5r+Mr74Hx/d+I385rXvKaTpkuV7+iuvvrqdFN53n7kIx9JNxERO3bsKHVAjacRAAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYMDQaDwX79w6Ghg30uv5FDDz003Zxzzjnp5oUvfGG6ec5znpNujj322HQTETE6Oppudu/enW4effTRdHPnnXemm4iI66+/Pt189atfTTfbt29PN/1+P93AXNnP5f6AGB7O/x5VpamseRERU1NTpW6hqTzbKz+nXq+XbrpUuQ6Vz1Pl2lX3X5VjVf5Ps7Oz6WYh6uoe6lKX5zff3zMA+N/N92fG2NhYupmZmUk3ERHLly9PN5XvZBYvXpxuzj333HTzsY99LN1ERJx66qnpZuvWrenm3nvvTTfXXHNNuomImJiYSDf//M//nG4q90PF+Ph4qZuenj7AZ/L4Ku/6Xb6bdLWuVH5OXf2MIiIWLVqUbvbt23cQzuTxec8AaNv+vmf4i24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaIpBNwAAAAAAAABNMegGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGiKQTcAAAAAAAAATTHoBgAAAAAAAKApQ4PBYLBf/3Bo6GCfy2/kqKOOSjevfOUr082FF16YbirnNjMzk24iIh566KF086Mf/Sjd3H333enm5ptvTjcREZs3b043vV6vdCxYyPZzuT8gunpmjIyMlLp+v9/JsWZnZ9NN5dp1+bOd74aH87/DV7kf+L+qn8Gs6nO9q7WocpzqfVe55pXrtxCfGQAcHF0+MyrPwS73emNjY+mm+v1PFxYvXlzqKtd8eno63YyOjqabyjtaVWWP0+W+cj7ras9b3YcuxHfwJUuWpJt9+/almy7vV+8ZAG3b3+etv+gGAAAAAAAAoCkG3QAAAAAAAAA0xaAbAAAAAAAAgKYYdAMAAAAAAADQFINuAAAAAAAAAJpi0A0AAAAAAABAUwy6AQAAAAAAAGiKQTcAAAAAAAAATTHoBgAAAAAAAKApBt0AAAAAAAAANMWgGwAAAAAAAICmGHQDAAAAAAAA0JTRuT6BA2Xfvn3pZuPGjenmF7/4RbrZs2dPunn00UfTTUTEL3/5y3Szbdu2dFO53r1eL90A/G+q68rQ0FC6mZ2dLR0razAYdHKcharysx0bG0s3MzMz8/Y4VZVrV7lf+/1+uqmq/J8q59fl57bL6wcA801Xz8HKvi1ifj+nK/uiync/EREjIyOlLqvyjrZs2bLSsSrf7VVU7qHR0fzXu5X7oary3t7Vd4jVffzwcDd/O1a5H6rrV+VadPVZB4D/jb/oBgAAAAAAAKApBt0AAAAAAAAANMWgGwAAAAAAAICmGHQDAAAAAAAA0BSDbgAAAAAAAACaYtANAAAAAAAAQFMMugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANCUocFgMJjrkwAAAAAAAACA/eUvugEAAAAAAABoikE3AAAAAAAAAE0x6AYAAAAAAACgKQbdAAAAAAAAADTFoBsAAAAAAACAphh0AwAAAAAAANAUg24AAAAAAAAAmmLQDQAAAAAAAEBTDLoBAAAAAAAAaMr/AerFRFNpsMuIAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in train dataset: 60000\n",
            "Number of samples in test dataset: 10000\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to visualize augmentations\n",
        "visualize_augmentations(train_loader.dataset)\n",
        "\n",
        "# # print number of samples in train and test dataset\n",
        "print(f\"Number of samples in train dataset: {len(train_loader.dataset)}\")\n",
        "print(f\"Number of samples in test dataset: {len(test_loader.dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.43125641345977783 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1647, Accuracy: 9605/10000 (96.05%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.24821193516254425 batch_id=117: 100%|██████████| 118/118 [00:10<00:00, 10.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1049, Accuracy: 9756/10000 (97.56%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.13243888318538666 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0625, Accuracy: 9840/10000 (98.40%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.1165132150053978 batch_id=117: 100%|██████████| 118/118 [00:10<00:00, 10.77it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0524, Accuracy: 9874/10000 (98.74%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.07822083681821823 batch_id=117: 100%|██████████| 118/118 [00:10<00:00, 10.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0447, Accuracy: 9888/10000 (98.88%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.11980058997869492 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0430, Accuracy: 9894/10000 (98.94%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.08553817868232727 batch_id=117: 100%|██████████| 118/118 [00:10<00:00, 10.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0407, Accuracy: 9894/10000 (98.94%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.08415036648511887 batch_id=117: 100%|██████████| 118/118 [00:10<00:00, 10.73it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0338, Accuracy: 9905/10000 (99.05%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.13259628415107727 batch_id=117: 100%|██████████| 118/118 [00:10<00:00, 10.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0353, Accuracy: 9905/10000 (99.05%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
