{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, 3, padding=1),  # 1*3*3*4 + 4 = 40 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(4),              # 8 params\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, 3, padding=1),  # 4*3*3*8 + 8 = 296 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),              # 16 params\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        \n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(8, 12, 3, padding=1), # 8*3*3*12 + 12 = 876 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),             # 24 params\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        \n",
        "        # 12 channels * 3 * 3 = 108 neurons after three max pools (28->14->7->3)\n",
        "        self.fc1 = nn.Linear(12 * 3 * 3, 10)  # 108*10 + 10 = 1090 params\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, 12 * 3 * 3)  # Flatten\n",
        "        x = F.dropout(x, p=0.1)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 4, 14, 14]            --\n",
              "│    └─Conv2d: 2-1                       [1, 4, 28, 28]            40\n",
              "│    └─ReLU: 2-2                         [1, 4, 28, 28]            --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 4, 28, 28]            8\n",
              "│    └─MaxPool2d: 2-4                    [1, 4, 14, 14]            --\n",
              "├─Sequential: 1-2                        [1, 8, 7, 7]              --\n",
              "│    └─Conv2d: 2-5                       [1, 8, 14, 14]            296\n",
              "│    └─ReLU: 2-6                         [1, 8, 14, 14]            --\n",
              "│    └─BatchNorm2d: 2-7                  [1, 8, 14, 14]            16\n",
              "│    └─MaxPool2d: 2-8                    [1, 8, 7, 7]              --\n",
              "│    └─Dropout: 2-9                      [1, 8, 7, 7]              --\n",
              "├─Sequential: 1-3                        [1, 12, 3, 3]             --\n",
              "│    └─Conv2d: 2-10                      [1, 12, 7, 7]             876\n",
              "│    └─ReLU: 2-11                        [1, 12, 7, 7]             --\n",
              "│    └─BatchNorm2d: 2-12                 [1, 12, 7, 7]             24\n",
              "│    └─MaxPool2d: 2-13                   [1, 12, 3, 3]             --\n",
              "│    └─Dropout: 2-14                     [1, 12, 3, 3]             --\n",
              "├─Linear: 1-4                            [1, 10]                   1,090\n",
              "==========================================================================================\n",
              "Total params: 2,350\n",
              "Trainable params: 2,350\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.08\n",
              "Params size (MB): 0.01\n",
              "Estimated Total Size (MB): 0.10\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "# Create a dummy input tensor on the correct device\n",
        "summary(model, input_size=(1, 1, 28, 28), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1456)\n",
        "batch_size = 512\n",
        "\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True} if device.type in [\"cuda\", \"mps\"] else {}\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=True, download=True,\n",
        "#                     transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "# Define the augmentation pipeline\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.0625,\n",
        "        scale_limit=0.1,\n",
        "        rotate_limit=15,\n",
        "        p=0.7,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.3),\n",
        "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
        "    A.Perspective(scale=(0.05, 0.1), p=0.3, keep_size=True, pad_mode=cv2.BORDER_CONSTANT, pad_val=0),\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Custom Dataset class to work with Albumentations\n",
        "class MNISTAlbumentations(datasets.MNIST):\n",
        "    def __init__(self, root, train=True, download=True, transform=None):\n",
        "        super().__init__(root, train=train, download=download, transform=None)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx], self.targets[idx]\n",
        "        \n",
        "        # Convert to numpy array and add channel dimension\n",
        "        img = np.array(img)\n",
        "        img = np.expand_dims(img, axis=-1)  # Add channel dimension for Albumentations\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=img)\n",
        "            img = transformed[\"image\"]\n",
        "            \n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Update the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=True, download=True, transform=train_transforms),\n",
        "    batch_size=batch_size, shuffle=True, \n",
        "    **kwargs)\n",
        "\n",
        "# Test transforms (only normalization, no augmentation)\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=False, transform=test_transforms),\n",
        "    batch_size=batch_size, shuffle=True,  \n",
        "    **kwargs)\n",
        "\n",
        "# Optional: Visualization function to check augmentations\n",
        "def visualize_augmentations(dataset, idx=0, samples=5):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(samples):\n",
        "        data = dataset[idx][0]\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            data = data.numpy()\n",
        "        if data.shape[0] == 1:  # If channels first, move to last\n",
        "            data = np.transpose(data, (1, 2, 0))\n",
        "        plt.subplot(1, samples, i + 1)\n",
        "        plt.imshow(data.squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in train dataset: 60000\n",
            "Number of samples in test dataset: 10000\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to visualize augmentations\n",
        "visualize_augmentations(train_loader.dataset)\n",
        "\n",
        "# # print number of samples in train and test dataset\n",
        "print(f\"Number of samples in train dataset: {len(train_loader.dataset)}\")\n",
        "print(f\"Number of samples in test dataset: {len(test_loader.dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.34809982776641846 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1105, Accuracy: 9650/10000 (96.50%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.22995877265930176 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0784, Accuracy: 9741/10000 (97.41%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.14917902648448944 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0729, Accuracy: 9757/10000 (97.57%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.2511812150478363 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.00it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0718, Accuracy: 9753/10000 (97.53%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.21326041221618652 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0636, Accuracy: 9787/10000 (97.87%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.12657733261585236 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0597, Accuracy: 9803/10000 (98.03%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.24827630817890167 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0620, Accuracy: 9801/10000 (98.01%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.1275600641965866 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.93it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0590, Accuracy: 9815/10000 (98.15%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.14013992249965668 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0566, Accuracy: 9814/10000 (98.14%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "# scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "#     optimizer, \n",
        "#     max_lr=0.1,\n",
        "#     epochs=10,\n",
        "#     steps_per_epoch=len(train_loader)\n",
        "# )\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
