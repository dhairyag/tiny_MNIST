{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, 3, padding=1),  # 1*3*3*4 + 4 = 40 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(4),              # 8 params\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, 3, padding=1),  # 4*3*3*8 + 8 = 296 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),              # 16 params\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        \n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(8, 12, 3, padding=1), # 8*3*3*12 + 12 = 876 params\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),             # 24 params\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        \n",
        "        # 12 channels * 3 * 3 = 108 neurons after three max pools (28->14->7->3)\n",
        "        self.fc1 = nn.Linear(12 * 3 * 3, 10)  # 108*10 + 10 = 1090 params\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, 12 * 3 * 3)  # Flatten\n",
        "        x = F.dropout(x, p=0.1)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 4, 14, 14]            --\n",
              "│    └─Conv2d: 2-1                       [1, 4, 28, 28]            40\n",
              "│    └─ReLU: 2-2                         [1, 4, 28, 28]            --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 4, 28, 28]            8\n",
              "│    └─MaxPool2d: 2-4                    [1, 4, 14, 14]            --\n",
              "├─Sequential: 1-2                        [1, 8, 7, 7]              --\n",
              "│    └─Conv2d: 2-5                       [1, 8, 14, 14]            296\n",
              "│    └─ReLU: 2-6                         [1, 8, 14, 14]            --\n",
              "│    └─BatchNorm2d: 2-7                  [1, 8, 14, 14]            16\n",
              "│    └─MaxPool2d: 2-8                    [1, 8, 7, 7]              --\n",
              "│    └─Dropout: 2-9                      [1, 8, 7, 7]              --\n",
              "├─Sequential: 1-3                        [1, 12, 3, 3]             --\n",
              "│    └─Conv2d: 2-10                      [1, 12, 7, 7]             876\n",
              "│    └─ReLU: 2-11                        [1, 12, 7, 7]             --\n",
              "│    └─BatchNorm2d: 2-12                 [1, 12, 7, 7]             24\n",
              "│    └─MaxPool2d: 2-13                   [1, 12, 3, 3]             --\n",
              "│    └─Dropout: 2-14                     [1, 12, 3, 3]             --\n",
              "├─Linear: 1-4                            [1, 10]                   1,090\n",
              "==========================================================================================\n",
              "Total params: 2,350\n",
              "Trainable params: 2,350\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.08\n",
              "Params size (MB): 0.01\n",
              "Estimated Total Size (MB): 0.10\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "# Create a dummy input tensor on the correct device\n",
        "summary(model, input_size=(1, 1, 28, 28), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/dhairyashil/miniconda3/envs/erav2/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1456)\n",
        "batch_size = 512\n",
        "\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True} if device.type in [\"cuda\", \"mps\"] else {}\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=True, download=True,\n",
        "#                     transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "#                         transforms.ToTensor(),\n",
        "#                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                     ])),\n",
        "#     batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "# Define the augmentation pipeline\n",
        "train_transforms = A.Compose([\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.0625,\n",
        "        scale_limit=0.1,\n",
        "        rotate_limit=15,\n",
        "        p=0.7,\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        value=0\n",
        "    ),\n",
        "    A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.3),\n",
        "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
        "    A.Perspective(scale=(0.05, 0.1), p=0.3, keep_size=True, pad_mode=cv2.BORDER_CONSTANT, pad_val=0),\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Custom Dataset class to work with Albumentations\n",
        "class MNISTAlbumentations(datasets.MNIST):\n",
        "    def __init__(self, root, train=True, download=True, transform=None):\n",
        "        super().__init__(root, train=train, download=download, transform=None)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx], self.targets[idx]\n",
        "        \n",
        "        # Convert to numpy array and add channel dimension\n",
        "        img = np.array(img)\n",
        "        img = np.expand_dims(img, axis=-1)  # Add channel dimension for Albumentations\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=img)\n",
        "            img = transformed[\"image\"]\n",
        "            \n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Update the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=True, download=True, transform=train_transforms),\n",
        "    batch_size=batch_size, shuffle=True, \n",
        "    **kwargs)\n",
        "\n",
        "# Test transforms (only normalization, no augmentation)\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(\n",
        "        mean=[0.1307],\n",
        "        std=[0.3081],\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    MNISTAlbumentations('../data', train=False, transform=test_transforms),\n",
        "    batch_size=batch_size, shuffle=True,  \n",
        "    **kwargs)\n",
        "\n",
        "# Optional: Visualization function to check augmentations\n",
        "def visualize_augmentations(dataset, idx=0, samples=5):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(samples):\n",
        "        data = dataset[idx][0]\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            data = data.numpy()\n",
        "        if data.shape[0] == 1:  # If channels first, move to last\n",
        "            data = np.transpose(data, (1, 2, 0))\n",
        "        plt.subplot(1, samples, i + 1)\n",
        "        plt.imshow(data.squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in train dataset: 60000\n",
            "Number of samples in test dataset: 10000\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to visualize augmentations\n",
        "visualize_augmentations(train_loader.dataset)\n",
        "\n",
        "# # print number of samples in train and test dataset\n",
        "print(f\"Number of samples in train dataset: {len(train_loader.dataset)}\")\n",
        "print(f\"Number of samples in test dataset: {len(test_loader.dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.47548428177833557 batch_id=117: 100%|██████████| 118/118 [00:12<00:00,  9.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1869, Accuracy: 9438/10000 (94.38%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.23641039431095123 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1232, Accuracy: 9610/10000 (96.10%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.24487586319446564 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0938, Accuracy: 9707/10000 (97.07%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.36239543557167053 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0814, Accuracy: 9761/10000 (97.61%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.27750980854034424 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0726, Accuracy: 9785/10000 (97.85%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.2665644884109497 batch_id=117: 100%|██████████| 118/118 [00:11<00:00,  9.89it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0684, Accuracy: 9796/10000 (97.96%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.2533153295516968 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.08it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0612, Accuracy: 9823/10000 (98.23%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.20092236995697021 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0596, Accuracy: 9810/10000 (98.10%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.31311413645744324 batch_id=117: 100%|██████████| 118/118 [00:11<00:00, 10.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0547, Accuracy: 9831/10000 (98.31%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
