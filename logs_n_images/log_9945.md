The complete log file is [here](./log_9945.md).

## Log Output
```bash
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      [1, 10]                   --
├─Sequential: 1-1                        [1, 6, 14, 14]            --
│    └─Conv2d: 2-1                       [1, 6, 28, 28]            60
│    └─BatchNorm2d: 2-2                  [1, 6, 28, 28]            12
│    └─ReLU: 2-3                         [1, 6, 28, 28]            --
│    └─Conv2d: 2-4                       [1, 6, 28, 28]            330
│    └─BatchNorm2d: 2-5                  [1, 6, 28, 28]            12
│    └─ReLU: 2-6                         [1, 6, 28, 28]            --
│    └─MaxPool2d: 2-7                    [1, 6, 14, 14]            --
│    └─Dropout: 2-8                      [1, 6, 14, 14]            --
├─Sequential: 1-2                        [1, 8, 7, 7]              --
│    └─Conv2d: 2-9                       [1, 8, 14, 14]            440
│    └─BatchNorm2d: 2-10                 [1, 8, 14, 14]            16
│    └─ReLU: 2-11                        [1, 8, 14, 14]            --
│    └─Conv2d: 2-12                      [1, 8, 14, 14]            584
│    └─BatchNorm2d: 2-13                 [1, 8, 14, 14]            16
│    └─ReLU: 2-14                        [1, 8, 14, 14]            --
│    └─MaxPool2d: 2-15                   [1, 8, 7, 7]              --
│    └─Dropout: 2-16                     [1, 8, 7, 7]              --
├─Sequential: 1-3                        [1, 10, 3, 3]             --
│    └─Conv2d: 2-17                      [1, 10, 7, 7]             730
│    └─BatchNorm2d: 2-18                 [1, 10, 7, 7]             20
│    └─ReLU: 2-19                        [1, 10, 7, 7]             --
│    └─MaxPool2d: 2-20                   [1, 10, 3, 3]             --
│    └─Dropout: 2-21                     [1, 10, 3, 3]             --
├─Linear: 1-4                            [1, 10]                   910
==========================================================================================
Total params: 3,130
Trainable params: 3,130
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.54
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.21
Params size (MB): 0.01
Estimated Total Size (MB): 0.22
==========================================================================================

Training with parameters:
max_lr: 0.4, initial_div: 25, final_div: 175
warmup_pct: 0.5, momentum: 0.9, weight_decay: 0.0005
---- Epoch : 01 |  learning_rate : 0.0160000 ----
Training set: loss=0.23329 accuracy=79.53% batch_id=117: 100%|████████████████████████████| 118/118 [00:03<00:00, 35.80it/s]
Test set: Average loss: 0.12921, Accuracy: 9579/10000 (95.79%)

---- Epoch : 02 |  learning_rate : 0.0254130 ----
Training set: loss=0.07729 accuracy=94.77% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.18it/s]
Test set: Average loss: 0.06101, Accuracy: 9803/10000 (98.03%)

---- Epoch : 03 |  learning_rate : 0.0527289 ----
Training set: loss=0.10971 accuracy=95.96% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.21it/s]
Test set: Average loss: 0.06226, Accuracy: 9808/10000 (98.08%)

---- Epoch : 04 |  learning_rate : 0.0952694 ----
Training set: loss=0.06744 accuracy=96.50% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.20it/s]
Test set: Average loss: 0.05408, Accuracy: 9810/10000 (98.10%)

---- Epoch : 05 |  learning_rate : 0.1488634 ----
Training set: loss=0.09990 accuracy=96.91% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.50it/s]
Test set: Average loss: 0.04919, Accuracy: 9834/10000 (98.34%)

---- Epoch : 06 |  learning_rate : 0.2082558 ----
Training set: loss=0.04150 accuracy=96.92% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.25it/s]
Test set: Average loss: 0.03982, Accuracy: 9865/10000 (98.65%)

---- Epoch : 07 |  learning_rate : 0.2676231 ----
Training set: loss=0.10130 accuracy=97.21% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.60it/s]
Test set: Average loss: 0.07059, Accuracy: 9764/10000 (97.64%)

---- Epoch : 08 |  learning_rate : 0.3211443 ----
Training set: loss=0.05310 accuracy=97.21% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.08it/s]
Test set: Average loss: 0.04528, Accuracy: 9849/10000 (98.49%)

---- Epoch : 09 |  learning_rate : 0.3635715 ----
Training set: loss=0.06064 accuracy=97.55% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.05it/s]
Test set: Average loss: 0.10073, Accuracy: 9667/10000 (96.67%)

---- Epoch : 10 |  learning_rate : 0.3907446 ----
Training set: loss=0.08891 accuracy=97.42% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.89it/s]
Test set: Average loss: 0.05091, Accuracy: 9838/10000 (98.38%)

---- Epoch : 11 |  learning_rate : 0.3999993 ----
Training set: loss=0.13766 accuracy=97.53% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.01it/s]
Test set: Average loss: 0.06332, Accuracy: 9801/10000 (98.01%)

---- Epoch : 12 |  learning_rate : 0.3900484 ----
Training set: loss=0.11048 accuracy=97.51% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.44it/s]
Test set: Average loss: 0.04928, Accuracy: 9845/10000 (98.45%)

---- Epoch : 13 |  learning_rate : 0.3614986 ----
Training set: loss=0.05290 accuracy=97.60% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.87it/s]
Test set: Average loss: 0.02727, Accuracy: 9916/10000 (99.16%)

---- Epoch : 14 |  learning_rate : 0.3171448 ----
Training set: loss=0.02015 accuracy=97.87% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.77it/s]
Test set: Average loss: 0.03759, Accuracy: 9888/10000 (98.88%)

---- Epoch : 15 |  learning_rate : 0.2613285 ----
Training set: loss=0.01088 accuracy=97.89% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.12it/s]
Test set: Average loss: 0.03168, Accuracy: 9892/10000 (98.92%)

---- Epoch : 16 |  learning_rate : 0.1995134 ----
Training set: loss=0.02929 accuracy=97.99% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.25it/s]
Test set: Average loss: 0.04322, Accuracy: 9860/10000 (98.60%)

---- Epoch : 17 |  learning_rate : 0.1377504 ----
Training set: loss=0.02706 accuracy=98.17% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.31it/s]
Test set: Average loss: 0.04599, Accuracy: 9852/10000 (98.52%)

---- Epoch : 18 |  learning_rate : 0.0820853 ----
Training set: loss=0.00872 accuracy=98.35% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.58it/s]
Test set: Average loss: 0.02212, Accuracy: 9936/10000 (99.36%)

---- Epoch : 19 |  learning_rate : 0.0379670 ----
Training set: loss=0.02346 accuracy=98.60% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.95it/s]
Test set: Average loss: 0.02101, Accuracy: 9939/10000 (99.39%)

---- Epoch : 20 |  learning_rate : 0.0097141 ----
Training set: loss=0.00302 accuracy=98.66% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.12it/s]
Test set: Average loss: 0.02014, Accuracy: 9945/10000 (99.45%)

```