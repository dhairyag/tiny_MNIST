The complete log file is [here](./log_9943.md).

## Log Output
```bash
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      [1, 10]                   --
├─Sequential: 1-1                        [1, 6, 14, 14]            --
│    └─Conv2d: 2-1                       [1, 6, 28, 28]            60
│    └─BatchNorm2d: 2-2                  [1, 6, 28, 28]            12
│    └─ReLU: 2-3                         [1, 6, 28, 28]            --
│    └─Conv2d: 2-4                       [1, 6, 28, 28]            330
│    └─BatchNorm2d: 2-5                  [1, 6, 28, 28]            12
│    └─ReLU: 2-6                         [1, 6, 28, 28]            --
│    └─MaxPool2d: 2-7                    [1, 6, 14, 14]            --
│    └─Dropout: 2-8                      [1, 6, 14, 14]            --
├─Sequential: 1-2                        [1, 8, 7, 7]              --
│    └─Conv2d: 2-9                       [1, 8, 14, 14]            440
│    └─BatchNorm2d: 2-10                 [1, 8, 14, 14]            16
│    └─ReLU: 2-11                        [1, 8, 14, 14]            --
│    └─Conv2d: 2-12                      [1, 8, 14, 14]            584
│    └─BatchNorm2d: 2-13                 [1, 8, 14, 14]            16
│    └─ReLU: 2-14                        [1, 8, 14, 14]            --
│    └─MaxPool2d: 2-15                   [1, 8, 7, 7]              --
│    └─Dropout: 2-16                     [1, 8, 7, 7]              --
├─Sequential: 1-3                        [1, 10, 3, 3]             --
│    └─Conv2d: 2-17                      [1, 10, 7, 7]             730
│    └─BatchNorm2d: 2-18                 [1, 10, 7, 7]             20
│    └─ReLU: 2-19                        [1, 10, 7, 7]             --
│    └─MaxPool2d: 2-20                   [1, 10, 3, 3]             --
│    └─Dropout: 2-21                     [1, 10, 3, 3]             --
├─Linear: 1-4                            [1, 10]                   910
==========================================================================================
Total params: 3,130
Trainable params: 3,130
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.54
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.21
Params size (MB): 0.01
Estimated Total Size (MB): 0.22
==========================================================================================

Training with parameters:
max_lr: 0.4, initial_div: 25, final_div: 175
warmup_pct: 0.5, momentum: 0.95, weight_decay: 0.0005
---- Epoch : 01 |  learning_rate : 0.0160000 ----
Training set: loss=0.12219 accuracy=82.10% batch_id=117: 100%|████████████████████████████| 118/118 [00:03<00:00, 36.71it/s]
Test set: Average loss: 0.09101, Accuracy: 9727/10000 (97.27%)

---- Epoch : 02 |  learning_rate : 0.0254130 ----
Training set: loss=0.16564 accuracy=95.99% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.76it/s]
Test set: Average loss: 0.06876, Accuracy: 9801/10000 (98.01%)

---- Epoch : 03 |  learning_rate : 0.0527289 ----
Training set: loss=0.04348 accuracy=97.11% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.55it/s]
Test set: Average loss: 0.08272, Accuracy: 9740/10000 (97.40%)

---- Epoch : 04 |  learning_rate : 0.0952694 ----
Training set: loss=0.07293 accuracy=97.31% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.74it/s]
Test set: Average loss: 0.09606, Accuracy: 9706/10000 (97.06%)

---- Epoch : 05 |  learning_rate : 0.1488634 ----
Training set: loss=0.02403 accuracy=97.67% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.24it/s]
Test set: Average loss: 0.08276, Accuracy: 9737/10000 (97.37%)

---- Epoch : 06 |  learning_rate : 0.2082558 ----
Training set: loss=0.06534 accuracy=97.71% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.38it/s]
Test set: Average loss: 0.05669, Accuracy: 9816/10000 (98.16%)

---- Epoch : 07 |  learning_rate : 0.2676231 ----
Training set: loss=0.05291 accuracy=97.80% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.72it/s]
Test set: Average loss: 0.08123, Accuracy: 9743/10000 (97.43%)

---- Epoch : 08 |  learning_rate : 0.3211443 ----
Training set: loss=0.02430 accuracy=97.83% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.83it/s]
Test set: Average loss: 0.05404, Accuracy: 9811/10000 (98.11%)

---- Epoch : 09 |  learning_rate : 0.3635715 ----
Training set: loss=0.03378 accuracy=98.01% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.33it/s]
Test set: Average loss: 0.03644, Accuracy: 9879/10000 (98.79%)

---- Epoch : 10 |  learning_rate : 0.3907446 ----
Training set: loss=0.02392 accuracy=98.06% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.91it/s]
Test set: Average loss: 0.05692, Accuracy: 9800/10000 (98.00%)

---- Epoch : 11 |  learning_rate : 0.3999993 ----
Training set: loss=0.01994 accuracy=98.11% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.31it/s]
Test set: Average loss: 0.06805, Accuracy: 9792/10000 (97.92%)

---- Epoch : 12 |  learning_rate : 0.3900484 ----
Training set: loss=0.02440 accuracy=98.20% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.94it/s]
Test set: Average loss: 0.03041, Accuracy: 9904/10000 (99.04%)

---- Epoch : 13 |  learning_rate : 0.3614986 ----
Training set: loss=0.22233 accuracy=98.18% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.24it/s]
Test set: Average loss: 0.16481, Accuracy: 9506/10000 (95.06%)

---- Epoch : 14 |  learning_rate : 0.3171448 ----
Training set: loss=0.10581 accuracy=98.27% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.40it/s]
Test set: Average loss: 0.05192, Accuracy: 9848/10000 (98.48%)

---- Epoch : 15 |  learning_rate : 0.2613285 ----
Training set: loss=0.04114 accuracy=98.37% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.13it/s]
Test set: Average loss: 0.03332, Accuracy: 9893/10000 (98.93%)

---- Epoch : 16 |  learning_rate : 0.1995134 ----
Training set: loss=0.03080 accuracy=98.47% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.05it/s]
Test set: Average loss: 0.02844, Accuracy: 9907/10000 (99.07%)

---- Epoch : 17 |  learning_rate : 0.1377504 ----
Training set: loss=0.03657 accuracy=98.68% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.53it/s]
Test set: Average loss: 0.02901, Accuracy: 9913/10000 (99.13%)

---- Epoch : 18 |  learning_rate : 0.0820853 ----
Training set: loss=0.01235 accuracy=98.75% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.39it/s]
Test set: Average loss: 0.02275, Accuracy: 9929/10000 (99.29%)

---- Epoch : 19 |  learning_rate : 0.0379670 ----
Training set: loss=0.04414 accuracy=98.96% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 42.21it/s]
Test set: Average loss: 0.01916, Accuracy: 9940/10000 (99.40%)

---- Epoch : 20 |  learning_rate : 0.0097141 ----
Training set: loss=0.01139 accuracy=99.06% batch_id=117: 100%|████████████████████████████| 118/118 [00:02<00:00, 41.32it/s]
Test set: Average loss: 0.01900, Accuracy: 9943/10000 (99.43%)
```